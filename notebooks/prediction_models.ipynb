{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle League of Legends competition - ML Models\n",
    "\n",
    "## Team: Elden Ring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://eldenring.wiki.fextralife.com/file/Elden-Ring/mirel_pastor_of_vow.jpg\" alt=\"PRAISE DOG\" style=\"width:806px;height:600px;\"/>\n",
    "\n",
    "#### PRAISE THE DOG!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Win at League of Legends?\n",
    "\n",
    "### Uninstall LoL and [install Dota 2](https://store.steampowered.com/app/570/Dota_2/), EZ.\n",
    "\n",
    "<img src = \"https://static.wikia.nocookie.net/dota2_gamepedia/images/7/78/Keyart_phoenix.jpg/revision/latest/\" alt=\"SKREE CAW CAW IM A BIRD\" style=\"width:800px;height:497px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = pd.read_csv('../data/participants_train.csv')\n",
    "X_test_original = pd.read_csv('../data/participants_test.csv')\n",
    "y_train_original = pd.read_csv('../data/train_winners.csv')\n",
    "\n",
    "champion_mastery = pd.read_csv('../data/champion_mastery.csv')\n",
    "champion = pd.read_json('../data/champion.json')\n",
    "team_positions = pd.read_csv('../data/teamPositions.csv')\n",
    "\n",
    "submission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that converts values to negative (for the second team, teamId 200)\n",
    "# it leaves the first team values, teamId intact\n",
    "\n",
    "def convert_team_values(df, col_names):\n",
    "    \n",
    "    \n",
    "    for col in col_names:\n",
    "        df[col] = np.where(df['teamId'] == 200,\n",
    "                            -1* df[col],\n",
    "                                df[col])\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used later to measure the accuracy!\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to extract the column that is needed for training\n",
    "y_train = y_train_original['winner']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating Sample Submission as LogReg\n",
    "\n",
    "In order to replicate it, I will take the max from each SummonerLevel per match & teamId combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to fit on\n",
    "variables = ['summonerLevel']\n",
    "\n",
    "# first copy the original data to not accidentally change it\n",
    "X_train = X_train_original\n",
    "\n",
    "# find the max Summoner Level per each team\n",
    "X_train = X_train.groupby(['matchId', 'teamId'])[variables].max().reset_index()\n",
    "\n",
    "# mark them as positive (first team) or negative (second team), to compare the values\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "# finally, see which team has max summoner level (by adding the + and - from before)\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03635984]\n",
      "[[-9.10448626e-05]]\n",
      "[-399.36181513]\n"
     ]
    }
   ],
   "source": [
    "print(logreg.intercept_)\n",
    "print(logreg.coef_)\n",
    "print(- logreg.intercept_[0] / logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100, 100, 100, ..., 100, 200, 100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = logreg.predict(X_train)\n",
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50925"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = y_predictions\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: successfully replicated, with slightly better prediction, 50.9% with respect to 50.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5     0.50125 0.5     0.47375 0.5225  0.51125 0.5     0.50375 0.52875\n",
      " 0.505  ]\n",
      "0.504625\n"
     ]
    }
   ],
   "source": [
    "base_cv_scores = cross_val_score(\n",
    "    estimator = logreg,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(base_cv_scores)\n",
    "print(np.mean(base_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now LogReg with Champion mastery added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: found out champion lvl is actually more indicative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel']\n",
    "\n",
    "X_train = X_train.groupby(['matchId', 'teamId'])[variables].agg({'summonerLevel': 'max', 'championLevel': 'sum'}).reset_index()\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mastery = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5525"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_mastery.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56625 0.57125 0.5325  0.545   0.545   0.55375 0.5475  0.53875 0.5525\n",
      " 0.55875]\n",
      "0.5511250000000001\n"
     ]
    }
   ],
   "source": [
    "mastery_cv_scores = cross_val_score(\n",
    "    estimator = logreg_mastery,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(mastery_cv_scores)\n",
    "print(np.mean(mastery_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         100       0.56      0.60      0.58      4071\n",
      "         200       0.55      0.51      0.53      3929\n",
      "\n",
      "    accuracy                           0.55      8000\n",
      "   macro avg       0.55      0.55      0.55      8000\n",
      "weighted avg       0.55      0.55      0.55      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, logreg_mastery.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2425 1646]\n",
      " [1934 1995]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, logreg_mastery.predict(X_train)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking into other Champion info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "champion_data = pd.json_normalize(champion['data'])\n",
    "champion_data['key'] = champion_data['key'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel', 'info.attack', 'info.defense', 'info.magic', 'info.difficulty']\n",
    "\n",
    "X_train = pd.merge(X_train_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "X_train = pd.merge(X_train, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'info.attack': 'sum',\n",
    "          'info.defense': 'sum',\n",
    "          'info.magic': 'sum',\n",
    "          'info.difficulty': 'sum'}).reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mastery_champion = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_mastery_champion.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57625 0.5725  0.5275  0.5825  0.5625  0.5775  0.555   0.545   0.555\n",
      " 0.56125]\n",
      "0.5615\n"
     ]
    }
   ],
   "source": [
    "mastery_champion_cv_scores = cross_val_score(\n",
    "    estimator = logreg_mastery_champion,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(mastery_champion_cv_scores)\n",
    "print(np.mean(mastery_champion_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this was done on 3/24/2023 for submission!\n",
    "\n",
    "variables = ['summonerLevel', 'championLevel', 'info.attack', 'info.defense', 'info.magic', 'info.difficulty']\n",
    "\n",
    "X_test = pd.merge(X_test_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "X_test = pd.merge(X_test, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_test = X_test.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_test = (\n",
    "    X_test\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'info.attack': 'sum',\n",
    "          'info.defense': 'sum',\n",
    "          'info.magic': 'sum',\n",
    "          'info.difficulty': 'sum'}).reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_test, variables)\n",
    "\n",
    "X_test = X_test.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg_mastery_champion.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  winner\n",
       "0     8000     100\n",
       "1     8001     100\n",
       "2     8002     100\n",
       "3     8003     100\n",
       "4     8004     200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['winner'] = y_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../data/submission_summonerlvl_champmastery_2023_03_24.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another idea: looking at individual players summoner\n",
    "\n",
    "so instead of taking the max, trating each as an individual variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_original.pivot_table(values='summonerLevel', index='matchId', columns='participantId').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_summoner = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.514125"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_summoner.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5     0.5     0.505   0.47375 0.50375 0.495   0.5     0.51125 0.52375\n",
      " 0.48875]\n",
      "0.5001249999999999\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_summoner,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like accounting for individual summoner's levels does not matter; however, let's try and account for the difference in same roles. Currently using just the summoner number, but eventially will use the champion level instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables= ['summonerLevel']\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby(['matchId', 'teamPosition'])[variables].sum().reset_index()\n",
    "\n",
    "X_train['lane_won'] = np.where(X_train[variables[0]] >= 0, 1, -1)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[['lane_won']].sum().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_summoner = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.508875"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_summoner.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5025  0.5525  0.49875 0.46875 0.5125  0.50875 0.515   0.4975  0.525\n",
      " 0.5075 ]\n",
      "0.5088750000000001\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_summoner,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to do the same, but using champion mastery per comparing the lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel']\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby(['matchId', 'teamPosition'])[variables].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['lane_summon_won'] = np.where(X_train[variables[0]] >= 0, 1, -1)\n",
    "\n",
    "conditions = [\n",
    "    X_train[variables[1]] > 0,\n",
    "    X_train[variables[1]] == 0,\n",
    "    X_train[variables[1]] < 0\n",
    "]\n",
    "\n",
    "values = [1, 0, -1]\n",
    "\n",
    "X_train['lane_champion_won'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.groupby('matchId')[['lane_summon_won', 'lane_champion_won']].sum().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_summoner = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.543625"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_summoner.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55875 0.53875 0.5325  0.5425  0.5375  0.55375 0.53125 0.5175  0.55875\n",
      " 0.54   ]\n",
      "0.541125\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_summoner,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5987625122070312e-05\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now().timestamp()\n",
    "end = dt.datetime.now().timestamp()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
