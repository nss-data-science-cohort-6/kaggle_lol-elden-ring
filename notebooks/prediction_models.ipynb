{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle League of Legends competition - ML Models\n",
    "\n",
    "## Team: Elden Ring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://eldenring.wiki.fextralife.com/file/Elden-Ring/mirel_pastor_of_vow.jpg\" alt=\"PRAISE DOG\" style=\"width:806px;height:600px;\"/>\n",
    "\n",
    "#### PRAISE THE DOG!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Win at League of Legends?\n",
    "\n",
    "### Uninstall LoL and [install Dota 2](https://store.steampowered.com/app/570/Dota_2/), EZ.\n",
    "\n",
    "<img src = \"https://static.wikia.nocookie.net/dota2_gamepedia/images/7/78/Keyart_phoenix.jpg/revision/latest/\" alt=\"SKREE CAW CAW IM A BIRD\" style=\"width:800px;height:497px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = pd.read_csv('../data/participants_train.csv')\n",
    "X_test_original = pd.read_csv('../data/participants_test.csv')\n",
    "y_train_original = pd.read_csv('../data/train_winners.csv')\n",
    "\n",
    "champion_mastery = pd.read_csv('../data/champion_mastery.csv')\n",
    "champion = pd.read_json('../data/champion.json')\n",
    "team_positions = pd.read_csv('../data/teamPositions.csv')\n",
    "\n",
    "submission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that converts values to negative (for the second team, teamId 200)\n",
    "# it leaves the first team values, teamId intact\n",
    "\n",
    "def convert_team_values(df, col_names):\n",
    "    \n",
    "    \n",
    "    for col in col_names:\n",
    "        df[col] = np.where(df['teamId'] == 200,\n",
    "                            -1* df[col],\n",
    "                                df[col])\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used later to measure the accuracy!\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to extract the column that is needed for training\n",
    "y_train = y_train_original['winner']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating Sample Submission as LogReg\n",
    "\n",
    "In order to replicate it, I will take the max from each SummonerLevel per match & teamId combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to fit on\n",
    "variables = ['summonerLevel']\n",
    "\n",
    "# first copy the original data to not accidentally change it\n",
    "X_train = X_train_original\n",
    "\n",
    "# find the max Summoner Level per each team\n",
    "X_train = X_train.groupby(['matchId', 'teamId'])[variables].max().reset_index()\n",
    "\n",
    "# mark them as positive (first team) or negative (second team), to compare the values\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "# finally, see which team has max summoner level (by adding the + and - from before)\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03635984]\n",
      "[[-9.10448626e-05]]\n",
      "[-399.36181513]\n"
     ]
    }
   ],
   "source": [
    "print(logreg.intercept_)\n",
    "print(logreg.coef_)\n",
    "print(- logreg.intercept_[0] / logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100, 100, 100, ..., 100, 200, 100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = logreg.predict(X_train)\n",
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50925"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = y_predictions\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: successfully replicated, with slightly better prediction, 50.9% with respect to 50.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5     0.50125 0.5     0.47375 0.5225  0.51125 0.5     0.50375 0.52875\n",
      " 0.505  ]\n",
      "0.504625\n"
     ]
    }
   ],
   "source": [
    "base_cv_scores = cross_val_score(\n",
    "    estimator = logreg,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(base_cv_scores)\n",
    "print(np.mean(base_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now LogReg with Champion mastery added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: found out champion lvl is actually more indicative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel']\n",
    "\n",
    "X_train = X_train.groupby(['matchId', 'teamId'])[variables].agg({'summonerLevel': 'max', 'championLevel': 'sum'}).reset_index()\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mastery = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5525"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_mastery.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56625 0.57125 0.5325  0.545   0.545   0.55375 0.5475  0.53875 0.5525\n",
      " 0.55875]\n",
      "0.5511250000000001\n"
     ]
    }
   ],
   "source": [
    "mastery_cv_scores = cross_val_score(\n",
    "    estimator = logreg_mastery,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(mastery_cv_scores)\n",
    "print(np.mean(mastery_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         100       0.56      0.60      0.58      4071\n",
      "         200       0.55      0.51      0.53      3929\n",
      "\n",
      "    accuracy                           0.55      8000\n",
      "   macro avg       0.55      0.55      0.55      8000\n",
      "weighted avg       0.55      0.55      0.55      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, logreg_mastery.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2425 1646]\n",
      " [1934 1995]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, logreg_mastery.predict(X_train)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking into other Champion info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "champion_data = pd.json_normalize(champion['data'])\n",
    "champion_data['key'] = champion_data['key'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel', 'info.attack', 'info.defense', 'info.magic', 'info.difficulty']\n",
    "\n",
    "X_train = pd.merge(X_train_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "X_train = pd.merge(X_train, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'info.attack': 'sum',\n",
    "          'info.defense': 'sum',\n",
    "          'info.magic': 'sum',\n",
    "          'info.difficulty': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mastery_champion = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_mastery_champion.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57625 0.5725  0.5275  0.5825  0.5625  0.5775  0.555   0.545   0.555\n",
      " 0.56125]\n",
      "0.5615\n"
     ]
    }
   ],
   "source": [
    "mastery_champion_cv_scores = cross_val_score(\n",
    "    estimator = logreg_mastery_champion,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(mastery_champion_cv_scores)\n",
    "print(np.mean(mastery_champion_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this was done on 3/24/2023 for submission!\n",
    "\n",
    "variables = ['summonerLevel', 'championLevel', 'info.attack', 'info.defense', 'info.magic', 'info.difficulty']\n",
    "\n",
    "X_test = pd.merge(X_test_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "X_test = pd.merge(X_test, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_test = X_test.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_test = (\n",
    "    X_test\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'info.attack': 'sum',\n",
    "          'info.defense': 'sum',\n",
    "          'info.magic': 'sum',\n",
    "          'info.difficulty': 'sum'}).reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_test, variables)\n",
    "\n",
    "X_test = X_test.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg_mastery_champion.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  winner\n",
       "0     8000     100\n",
       "1     8001     100\n",
       "2     8002     100\n",
       "3     8003     100\n",
       "4     8004     200"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['winner'] = y_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../data/submission_summonerlvl_champmastery_2023_03_24.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "follow-up to use stats too (other than info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel', 'info.attack', 'info.defense', 'info.magic', 'info.difficulty', 'stats.hp', 'stats.attackdamage','stats.attackspeed']\n",
    "\n",
    "X_train = pd.merge(X_train_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "X_train = pd.merge(X_train, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'info.attack': 'sum',\n",
    "          'info.defense': 'sum',\n",
    "          'info.magic': 'sum',\n",
    "          'info.difficulty': 'sum',\n",
    "          'stats.hp': 'sum',\n",
    "          #'stats.hpperlevel': 'sum',\n",
    "          #'stats.mp': 'sum',\n",
    "          #'stats.mpperlevel': 'sum',\n",
    "          #'stats.movespeed': 'sum',\n",
    "          #'stats.armor': 'sum',\n",
    "          #'stats.armorperlevel': 'sum',\n",
    "          #'stats.spellblock': 'sum',\n",
    "          #'stats.spellblockperlevel': 'sum',\n",
    "          #'stats.attackrange': 'sum',\n",
    "          #'stats.hpregen': 'sum',\n",
    "          #'stats.hpregenperlevel': 'sum',\n",
    "          #'stats.mpregen': 'sum',\n",
    "          #'stats.mpregenperlevel': 'sum',\n",
    "          #'stats.crit': 'sum',\n",
    "          #'stats.critperlevel': 'sum',\n",
    "          'stats.attackdamage': 'sum',\n",
    "          #'stats.attackdamageperlevel': 'sum',\n",
    "          #'stats.attackspeedperlevel': 'sum',\n",
    "          'stats.attackspeed': 'sum'\n",
    "          })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mastery_champion_stats = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5645"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_mastery_champion_stats.predict(X_train)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another idea: looking at individual players summoner\n",
    "\n",
    "so instead of taking the max, trating each as an individual variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_original.pivot_table(values='summonerLevel', index='matchId', columns='participantId').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_summoner = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.514125"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_summoner.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5     0.5     0.505   0.47375 0.50375 0.495   0.5     0.51125 0.52375\n",
      " 0.48875]\n",
      "0.5001249999999999\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_summoner,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like accounting for individual summoner's levels does not matter; however, let's try and account for the difference in same roles. Currently using just the summoner number, but eventially will use the champion level instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables= ['summonerLevel']\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby(['matchId', 'teamPosition'])[variables].sum().reset_index()\n",
    "\n",
    "X_train['lane_won'] = np.where(X_train[variables[0]] >= 0, 1, -1)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[['lane_won']].sum().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_summoner = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.508875"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_summoner.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5025  0.5525  0.49875 0.46875 0.5125  0.50875 0.515   0.4975  0.525\n",
      " 0.5075 ]\n",
      "0.5088750000000001\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_summoner,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to do the same, but using champion mastery per comparing the lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel']\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby(['matchId', 'teamPosition'])[variables].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['lane_summon_won'] = np.where(X_train[variables[0]] >= 0, 1, -1)\n",
    "\n",
    "conditions = [\n",
    "    X_train[variables[1]] > 0,\n",
    "    X_train[variables[1]] == 0,\n",
    "    X_train[variables[1]] < 0\n",
    "]\n",
    "\n",
    "values = [1, 0, -1]\n",
    "\n",
    "X_train['lane_champion_won'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.groupby('matchId')[['lane_summon_won', 'lane_champion_won']].sum().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_summoner = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.543625"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_summoner.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55875 0.53875 0.5325  0.5425  0.5375  0.55375 0.53125 0.5175  0.55875\n",
      " 0.54   ]\n",
      "0.541125\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_summoner,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5987625122070312e-05\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now().timestamp()\n",
    "end = dt.datetime.now().timestamp()\n",
    "print(end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_frame_values = pd.read_csv('../data/last_frame_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>participantId</th>\n",
       "      <th>final_gold</th>\n",
       "      <th>final_xp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2741</td>\n",
       "      <td>4141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3045</td>\n",
       "      <td>2861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3545</td>\n",
       "      <td>4712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2789</td>\n",
       "      <td>2894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2026</td>\n",
       "      <td>2551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  participantId  final_gold  final_xp\n",
       "0        0              1        2741      4141\n",
       "1        0              2        3045      2861\n",
       "2        0              3        3545      4712\n",
       "3        0              4        2789      2894\n",
       "4        0              5        2026      2551"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_frame_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel',  'final_gold', 'final_xp']\n",
    "\n",
    "#'info.attack', 'info.defense', 'info.magic', 'info.difficulty',\n",
    "\n",
    "X_train = pd.merge(X_train_original, last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "#X_train = pd.merge(X_train, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "        #   'info.attack': 'sum',\n",
    "        #   'info.defense': 'sum',\n",
    "        #   'info.magic': 'sum',\n",
    "        #   'info.difficulty': 'sum',\n",
    "          'final_gold' : 'sum',\n",
    "          'final_xp': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_lastframe = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7075"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_lastframe.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72625 0.6975  0.7075  0.68875 0.70375 0.745   0.70125 0.68875 0.7275\n",
      " 0.67375]\n",
      "0.7060000000000001\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_lastframe,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Frames and Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel',  'final_gold', 'final_xp', 'final_armor', 'final_atkdmg', 'final_atkspd',\n",
    "             'final_health', 'final_healthrgn', 'final_lifesteal', 'final_mgpen', 'final_mgres', 'final_ms',\n",
    "             'final_dmgdone', 'final_dmgtaken', 'final_truedmgdone', 'final_truedmgtaken', 'final_lvl',\n",
    "             #'info.attack', 'info.defense', 'info.magic', 'info.difficulty'\n",
    "             ]\n",
    "\n",
    "#'info.attack', 'info.defense', 'info.magic', 'info.difficulty',\n",
    "\n",
    "X_train = pd.merge(X_train_original, last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "#X_train = pd.merge(X_train, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "        #    'info.attack': 'sum',\n",
    "        #    'info.defense': 'sum',\n",
    "        #    'info.magic': 'sum',\n",
    "        #    'info.difficulty': 'sum',\n",
    "          'final_gold' : 'sum',\n",
    "          'final_xp': 'sum',\n",
    "          'final_armor': 'sum',\n",
    "          'final_atkdmg': 'sum',\n",
    "          'final_atkspd': 'sum',\n",
    "          'final_health': 'sum',\n",
    "          'final_healthrgn': 'sum',\n",
    "          'final_lifesteal': 'sum',\n",
    "          'final_mgpen': 'sum',\n",
    "          'final_mgres': 'sum',\n",
    "          'final_ms': 'sum',\n",
    "          'final_dmgdone': 'sum',\n",
    "          'final_dmgtaken': 'sum',\n",
    "          'final_truedmgdone': 'sum',\n",
    "          'final_truedmgtaken': 'sum',\n",
    "          'final_lvl': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lastframe = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression())\n",
    "        # note: more steps can be added here ...\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lastframe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70975"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = pipeline_lastframe.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7275  0.69625 0.70875 0.705   0.70125 0.74125 0.7     0.69625 0.73\n",
      " 0.67   ]\n",
      "0.707625\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = pipeline_lastframe,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting the test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_last_frame_values = pd.read_csv('../data/test_last_frame_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel',  'final_gold', 'final_xp', 'final_armor', 'final_atkdmg', 'final_atkspd',\n",
    "             'final_health', 'final_healthrgn', 'final_lifesteal', 'final_mgpen', 'final_mgres', 'final_ms',\n",
    "             'final_dmgdone', 'final_dmgtaken', 'final_truedmgdone', 'final_truedmgtaken', 'final_lvl',\n",
    "             ]\n",
    "\n",
    "#'info.attack', 'info.defense', 'info.magic', 'info.difficulty',\n",
    "\n",
    "X_test = pd.merge(X_test_original, test_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_test = pd.merge(X_test, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "X_test = X_test.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_test = (\n",
    "    X_test\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'final_gold' : 'sum',\n",
    "          'final_xp': 'sum',\n",
    "          'final_armor': 'sum',\n",
    "          'final_atkdmg': 'sum',\n",
    "          'final_atkspd': 'sum',\n",
    "          'final_health': 'sum',\n",
    "          'final_healthrgn': 'sum',\n",
    "          'final_lifesteal': 'sum',\n",
    "          'final_mgpen': 'sum',\n",
    "          'final_mgres': 'sum',\n",
    "          'final_ms': 'sum',\n",
    "          'final_dmgdone': 'sum',\n",
    "          'final_dmgtaken': 'sum',\n",
    "          'final_truedmgdone': 'sum',\n",
    "          'final_truedmgtaken': 'sum',\n",
    "          'final_lvl': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_test, variables)\n",
    "\n",
    "X_test = X_test.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_lastframe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  winner\n",
       "0     8000     100\n",
       "1     8001     100\n",
       "2     8002     200\n",
       "3     8003     200\n",
       "4     8004     200"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['winner'] = y_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../data/submission_including_frames_2023_03_25.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
