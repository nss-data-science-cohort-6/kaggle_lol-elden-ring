{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle League of Legends competition - ML Models\n",
    "\n",
    "## Team: Elden Ring"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://eldenring.wiki.fextralife.com/file/Elden-Ring/mirel_pastor_of_vow.jpg\" alt=\"PRAISE DOG\" style=\"width:806px;height:600px;\"/>\n",
    "\n",
    "#### PRAISE THE DOG!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Win at League of Legends?\n",
    "\n",
    "### Uninstall LoL and [install Dota 2](https://store.steampowered.com/app/570/Dota_2/), EZ. (just kidding, both games are great. Volvo pls gib patch.)\n",
    "\n",
    "<img src = \"https://static.wikia.nocookie.net/dota2_gamepedia/images/7/78/Keyart_phoenix.jpg/revision/latest/\" alt=\"SKREE CAW CAW IM A BIRD\" style=\"width:800px;height:497px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = pd.read_csv('../data/participants_train.csv')\n",
    "X_test_original = pd.read_csv('../data/participants_test.csv')\n",
    "y_train_original = pd.read_csv('../data/train_winners.csv')\n",
    "\n",
    "champion_mastery = pd.read_csv('../data/champion_mastery.csv')\n",
    "champion = pd.read_json('../data/champion.json')\n",
    "team_positions = pd.read_csv('../data/teamPositions.csv')\n",
    "\n",
    "submission = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that converts values to negative (for the second team, teamId 200)\n",
    "# it leaves the first team values, teamId intact\n",
    "\n",
    "def convert_team_values(df, col_names):\n",
    "    \n",
    "    \n",
    "    for col in col_names:\n",
    "        df[col] = np.where(df['teamId'] == 200,\n",
    "                            -1* df[col],\n",
    "                                df[col])\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be used later to measure the accuracy!\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to extract the column that is needed for training\n",
    "y_train = y_train_original['winner']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating Sample Submission as LogReg\n",
    "\n",
    "In order to replicate it, I will take the max from each SummonerLevel per match & teamId combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to fit on\n",
    "variables = ['summonerLevel']\n",
    "\n",
    "# first copy the original data to not accidentally change it\n",
    "X_train = X_train_original\n",
    "\n",
    "# find the max Summoner Level per each team\n",
    "X_train = X_train.groupby(['matchId', 'teamId'])[variables].max().reset_index()\n",
    "\n",
    "# mark them as positive (first team) or negative (second team), to compare the values\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "# finally, see which team has max summoner level (by adding the + and - from before)\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100, 100, 100, ..., 100, 200, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predictions = logreg.predict(X_train)\n",
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50925"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = y_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5     0.50125 0.5     0.47375 0.5225  0.51125 0.5     0.50375 0.52875\n",
      " 0.505  ]\n",
      "0.504625\n"
     ]
    }
   ],
   "source": [
    "base_cv_scores = cross_val_score(\n",
    "    estimator = logreg,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(base_cv_scores)\n",
    "print(np.mean(base_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: successfully replicated!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now LogReg with Champion mastery added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.merge(X_train_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: found out champion lvl is actually more indicative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel']\n",
    "\n",
    "X_train = X_train.groupby(['matchId', 'teamId'])[variables].agg({'summonerLevel': 'max', 'championLevel': 'sum'}).reset_index()\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mastery = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5525"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_mastery.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56625 0.57125 0.5325  0.545   0.545   0.55375 0.5475  0.53875 0.5525\n",
      " 0.55875]\n",
      "0.5511250000000001\n"
     ]
    }
   ],
   "source": [
    "mastery_cv_scores = cross_val_score(\n",
    "    estimator = logreg_mastery,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(mastery_cv_scores)\n",
    "print(np.mean(mastery_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         100       0.56      0.60      0.58      4071\n",
      "         200       0.55      0.51      0.53      3929\n",
      "\n",
      "    accuracy                           0.55      8000\n",
      "   macro avg       0.55      0.55      0.55      8000\n",
      "weighted avg       0.55      0.55      0.55      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, logreg_mastery.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2425 1646]\n",
      " [1934 1995]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, logreg_mastery.predict(X_train)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking into other Champion info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "champion_data = pd.json_normalize(champion['data'])\n",
    "champion_data['key'] = champion_data['key'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel', 'info.attack', 'info.defense', 'info.magic', 'info.difficulty']\n",
    "\n",
    "X_train = pd.merge(X_train_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "X_train = pd.merge(X_train, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'info.attack': 'sum',\n",
    "          'info.defense': 'sum',\n",
    "          'info.magic': 'sum',\n",
    "          'info.difficulty': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mastery_champion = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.564625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_mastery_champion.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57625 0.5725  0.5275  0.5825  0.5625  0.5775  0.555   0.545   0.555\n",
      " 0.56125]\n",
      "0.5615\n"
     ]
    }
   ],
   "source": [
    "mastery_champion_cv_scores = cross_val_score(\n",
    "    estimator = logreg_mastery_champion,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(mastery_champion_cv_scores)\n",
    "print(np.mean(mastery_champion_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this was done on 3/24/2023 for submission!\n",
    "\n",
    "variables = ['summonerLevel', 'championLevel', 'info.attack', 'info.defense', 'info.magic', 'info.difficulty']\n",
    "\n",
    "X_test = pd.merge(X_test_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "X_test = pd.merge(X_test, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_test = X_test.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_test = (\n",
    "    X_test\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'info.attack': 'sum',\n",
    "          'info.defense': 'sum',\n",
    "          'info.magic': 'sum',\n",
    "          'info.difficulty': 'sum'}).reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_test, variables)\n",
    "\n",
    "X_test = X_test.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg_mastery_champion.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  winner\n",
       "0     8000     100\n",
       "1     8001     100\n",
       "2     8002     100\n",
       "3     8003     100\n",
       "4     8004     200"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['winner'] = y_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv('../data/submission_summonerlvl_champmastery_2023_03_24.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "follow-up to use stats too (other than info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel', 'info.attack', 'info.defense', 'info.magic', 'info.difficulty', 'stats.hp', 'stats.attackdamage','stats.attackspeed',\n",
    "            'stats.hpperlevel', 'stats.mp', 'stats.mpperlevel', 'stats.movespeed', 'stats.armor', 'stats.armorperlevel', 'stats.spellblock', 'stats.spellblockperlevel',\n",
    "            'stats.attackrange', 'stats.hpregen', 'stats.hpregenperlevel', 'stats.mpregen', 'stats.mpregenperlevel', 'stats.crit', 'stats.critperlevel',\n",
    "            'stats.attackdamageperlevel', 'stats.attackspeedperlevel']\n",
    "\n",
    "X_train = pd.merge(X_train_original, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "X_train = pd.merge(X_train, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'info.attack': 'sum',\n",
    "          'info.defense': 'sum',\n",
    "          'info.magic': 'sum',\n",
    "          'info.difficulty': 'sum',\n",
    "          'stats.hp': 'sum',\n",
    "          'stats.hpperlevel': 'sum',\n",
    "          'stats.mp': 'sum',\n",
    "          'stats.mpperlevel': 'sum',\n",
    "          'stats.movespeed': 'sum',\n",
    "          'stats.armor': 'sum',\n",
    "          'stats.armorperlevel': 'sum',\n",
    "          'stats.spellblock': 'sum',\n",
    "          'stats.spellblockperlevel': 'sum',\n",
    "          'stats.attackrange': 'sum',\n",
    "          'stats.hpregen': 'sum',\n",
    "          'stats.hpregenperlevel': 'sum',\n",
    "          'stats.mpregen': 'sum',\n",
    "          'stats.mpregenperlevel': 'sum',\n",
    "          'stats.crit': 'sum',\n",
    "          'stats.critperlevel': 'sum',\n",
    "          'stats.attackdamage': 'sum',\n",
    "          'stats.attackdamageperlevel': 'sum',\n",
    "          'stats.attackspeedperlevel': 'sum',\n",
    "          'stats.attackspeed': 'sum'\n",
    "          })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_mastery_champion_stats = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression())\n",
    "        # note: more steps can be added here ...\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_mastery_champion_stats.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = pipeline_mastery_champion_stats.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57    0.5575  0.52375 0.5425  0.54625 0.5725  0.55875 0.5625  0.58\n",
      " 0.5675 ]\n",
      "0.558125\n"
     ]
    }
   ],
   "source": [
    "mastery_champion_stats_cv_scores = cross_val_score(\n",
    "    estimator = pipeline_mastery_champion_stats,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(mastery_champion_stats_cv_scores)\n",
    "print(np.mean(mastery_champion_stats_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that adding the hero stats (pre-game) doesn't add much information beyond what is contained in the simple info!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another idea: looking at individual players summoner\n",
    "\n",
    "so instead of taking the max, trating each as an individual variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_original.pivot_table(values='summonerLevel', index='matchId', columns='participantId').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_summoner = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.514125"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_summoner.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5     0.5     0.505   0.47375 0.50375 0.495   0.5     0.51125 0.52375\n",
      " 0.48875]\n",
      "0.5001249999999999\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_summoner,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like accounting for individual summoner's levels does not matter; however, let's try and account for the difference in same roles. Currently using just the summoner number, but eventially will use the champion level instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables= ['summonerLevel']\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby(['matchId', 'teamPosition'])[variables].sum().reset_index()\n",
    "\n",
    "X_train['lane_won'] = np.where(X_train[variables[0]] >= 0, 1, -1)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[['lane_won']].sum().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_summoner = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.508875"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_summoner.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5025  0.5525  0.49875 0.46875 0.5125  0.50875 0.515   0.4975  0.525\n",
      " 0.5075 ]\n",
      "0.5088750000000001\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_summoner,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to do the same, but using champion mastery per comparing the lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel']\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby(['matchId', 'teamPosition'])[variables].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['lane_summon_won'] = np.where(X_train[variables[0]] >= 0, 1, -1)\n",
    "\n",
    "conditions = [\n",
    "    X_train[variables[1]] > 0,\n",
    "    X_train[variables[1]] == 0,\n",
    "    X_train[variables[1]] < 0\n",
    "]\n",
    "\n",
    "values = [1, 0, -1]\n",
    "\n",
    "X_train['lane_champion_won'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.groupby('matchId')[['lane_summon_won', 'lane_champion_won']].sum().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_summoner = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.543625"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_summoner.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55875 0.53875 0.5325  0.5425  0.5375  0.55375 0.53125 0.5175  0.55875\n",
      " 0.54   ]\n",
      "0.541125\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_summoner,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.504753112792969e-05\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now().timestamp()\n",
    "end = dt.datetime.now().timestamp()\n",
    "print(end - start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_last_frame_values = pd.read_csv('../data/train_last_frame_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>participantId</th>\n",
       "      <th>final_gold</th>\n",
       "      <th>final_xp</th>\n",
       "      <th>final_armor</th>\n",
       "      <th>final_atkdmg</th>\n",
       "      <th>final_atkspd</th>\n",
       "      <th>final_health</th>\n",
       "      <th>final_healthrgn</th>\n",
       "      <th>final_lifesteal</th>\n",
       "      <th>final_mgpen</th>\n",
       "      <th>final_mgres</th>\n",
       "      <th>final_ms</th>\n",
       "      <th>final_dmgdone</th>\n",
       "      <th>final_dmgtaken</th>\n",
       "      <th>final_truedmgdone</th>\n",
       "      <th>final_truedmgtaken</th>\n",
       "      <th>final_enemycontrolled</th>\n",
       "      <th>final_lvl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2741</td>\n",
       "      <td>4141</td>\n",
       "      <td>112</td>\n",
       "      <td>84</td>\n",
       "      <td>115</td>\n",
       "      <td>1525</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>335</td>\n",
       "      <td>3446</td>\n",
       "      <td>3965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11961</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3045</td>\n",
       "      <td>2861</td>\n",
       "      <td>53</td>\n",
       "      <td>72</td>\n",
       "      <td>238</td>\n",
       "      <td>1234</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>516</td>\n",
       "      <td>2471</td>\n",
       "      <td>10014</td>\n",
       "      <td>16</td>\n",
       "      <td>68</td>\n",
       "      <td>153462</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3545</td>\n",
       "      <td>4712</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>107</td>\n",
       "      <td>1325</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>350</td>\n",
       "      <td>2700</td>\n",
       "      <td>3835</td>\n",
       "      <td>359</td>\n",
       "      <td>583</td>\n",
       "      <td>58119</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2789</td>\n",
       "      <td>2894</td>\n",
       "      <td>51</td>\n",
       "      <td>114</td>\n",
       "      <td>125</td>\n",
       "      <td>1082</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>350</td>\n",
       "      <td>2112</td>\n",
       "      <td>2445</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>8159</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2026</td>\n",
       "      <td>2551</td>\n",
       "      <td>44</td>\n",
       "      <td>69</td>\n",
       "      <td>106</td>\n",
       "      <td>1102</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>360</td>\n",
       "      <td>1138</td>\n",
       "      <td>1376</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>86831</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  participantId  final_gold  final_xp  final_armor  final_atkdmg  \\\n",
       "0        0              1        2741      4141          112            84   \n",
       "1        0              2        3045      2861           53            72   \n",
       "2        0              3        3545      4712           56            70   \n",
       "3        0              4        2789      2894           51           114   \n",
       "4        0              5        2026      2551           44            69   \n",
       "\n",
       "   final_atkspd  final_health  final_healthrgn  final_lifesteal  final_mgpen  \\\n",
       "0           115          1525               26                0            7   \n",
       "1           238          1234               25                0            0   \n",
       "2           107          1325               20                0            0   \n",
       "3           125          1082               11                0            0   \n",
       "4           106          1102               14                0            0   \n",
       "\n",
       "   final_mgres  final_ms  final_dmgdone  final_dmgtaken  final_truedmgdone  \\\n",
       "0           43       335           3446            3965                  0   \n",
       "1           42       516           2471           10014                 16   \n",
       "2           37       350           2700            3835                359   \n",
       "3           35       350           2112            2445                  0   \n",
       "4           35       360           1138            1376                  0   \n",
       "\n",
       "   final_truedmgtaken  final_enemycontrolled  final_lvl  \n",
       "0                   0                  11961          8  \n",
       "1                  68                 153462          6  \n",
       "2                 583                  58119          8  \n",
       "3                  54                   8159          6  \n",
       "4                 235                  86831          6  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_last_frame_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel',  'final_gold', 'final_xp']\n",
    "\n",
    "#'info.attack', 'info.defense', 'info.magic', 'info.difficulty',\n",
    "\n",
    "X_train = pd.merge(X_train_original, train_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "#X_train = pd.merge(X_train, champion_data, how='inner', left_on='championId', right_on='key')\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "        #   'info.attack': 'sum',\n",
    "        #   'info.defense': 'sum',\n",
    "        #   'info.magic': 'sum',\n",
    "        #   'info.difficulty': 'sum',\n",
    "          'final_gold' : 'sum',\n",
    "          'final_xp': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_lastframe = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7075"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = logreg_lastframe.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72625 0.6975  0.7075  0.68875 0.70375 0.745   0.70125 0.68875 0.7275\n",
      " 0.67375]\n",
      "0.7060000000000001\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = logreg_lastframe,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Frames and Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel',  'final_gold', 'final_xp', 'final_armor', 'final_atkdmg', 'final_atkspd',\n",
    "             'final_health', 'final_healthrgn', 'final_lifesteal', 'final_mgpen', 'final_mgres', 'final_ms',\n",
    "             'final_dmgdone', 'final_dmgtaken', 'final_truedmgdone', 'final_truedmgtaken', 'final_lvl'\n",
    "             ]\n",
    "\n",
    "# found out later these are the important ones:\n",
    "# variables = ['summonerLevel', 'championLevel', 'final_gold', 'final_xp', 'final_armor', 'final_health', 'final_atkdmg']\n",
    "\n",
    "\n",
    "X_train = pd.merge(X_train_original, train_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'final_gold' : 'sum',\n",
    "          'final_xp': 'sum',\n",
    "          'final_armor': 'sum',\n",
    "          'final_atkdmg': 'sum',\n",
    "          'final_atkspd': 'sum',\n",
    "          'final_health': 'sum',\n",
    "          'final_healthrgn': 'sum',\n",
    "          'final_lifesteal': 'sum',\n",
    "          'final_mgpen': 'sum',\n",
    "          'final_mgres': 'sum',\n",
    "          'final_ms': 'sum',\n",
    "          'final_dmgdone': 'sum',\n",
    "          'final_dmgtaken': 'sum',\n",
    "          'final_truedmgdone': 'sum',\n",
    "          'final_truedmgtaken': 'sum',\n",
    "          'final_lvl': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train = X_train.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lastframe = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression())\n",
    "        # note: more steps can be added here ...\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lastframe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70975"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = pipeline_lastframe.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7275  0.69625 0.70875 0.705   0.70125 0.74125 0.7     0.69625 0.73\n",
      " 0.67   ]\n",
      "0.707625\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = pipeline_lastframe,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting the test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_last_frame_values = pd.read_csv('../data/test_last_frame_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['summonerLevel', 'championLevel',  'final_gold', 'final_xp', 'final_armor', 'final_atkdmg', 'final_atkspd',\n",
    "             'final_health', 'final_healthrgn', 'final_lifesteal', 'final_mgpen', 'final_mgres', 'final_ms',\n",
    "             'final_dmgdone', 'final_dmgtaken', 'final_truedmgdone', 'final_truedmgtaken', 'final_lvl',\n",
    "             ]\n",
    "\n",
    "#'info.attack', 'info.defense', 'info.magic', 'info.difficulty',\n",
    "\n",
    "X_test = pd.merge(X_test_original, test_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_test = pd.merge(X_test, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "X_test = X_test.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "X_test = (\n",
    "    X_test\n",
    "    .groupby(['matchId', 'teamId'])[variables]\n",
    "    .agg({'summonerLevel': 'max',\n",
    "          'championLevel': 'sum',\n",
    "          'final_gold' : 'sum',\n",
    "          'final_xp': 'sum',\n",
    "          'final_armor': 'sum',\n",
    "          'final_atkdmg': 'sum',\n",
    "          'final_atkspd': 'sum',\n",
    "          'final_health': 'sum',\n",
    "          'final_healthrgn': 'sum',\n",
    "          'final_lifesteal': 'sum',\n",
    "          'final_mgpen': 'sum',\n",
    "          'final_mgres': 'sum',\n",
    "          'final_ms': 'sum',\n",
    "          'final_dmgdone': 'sum',\n",
    "          'final_dmgtaken': 'sum',\n",
    "          'final_truedmgdone': 'sum',\n",
    "          'final_truedmgtaken': 'sum',\n",
    "          'final_lvl': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "convert_team_values(X_test, variables)\n",
    "\n",
    "X_test = X_test.groupby('matchId')[variables].sum().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_lastframe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  winner\n",
       "0     8000     100\n",
       "1     8001     100\n",
       "2     8002     200\n",
       "3     8003     200\n",
       "4     8004     200"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['winner'] = y_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This submission produced 70.4% on the Kaggle test set!!\n",
    "# submission.to_csv('../data/submission_including_frames_2023_03_25.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possibly Final idea: comparing the lanes individually and interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# champion types data make predictions worse!!\n",
    "champion_types= champion_data.explode('tags').pivot_table(values='id', index='key', columns='tags', aggfunc='count').fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['championLevel','final_gold', 'final_xp', 'final_armor', 'final_health', 'final_atkdmg',\n",
    "             #'Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank'\n",
    "             ]\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "#X_train = pd.merge(X_train, champion_types, how='inner', left_on='championId', right_on='key')\n",
    "X_train = pd.merge(X_train, train_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "# below doesn't make the model better\n",
    "# X_train[['Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank']] = X_train[['Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank']].multiply(X_train['championLevel'], axis='index')\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train_perlane = X_train.groupby(['matchId', 'teamPosition'])[['final_gold']].sum().pivot_table(values='final_gold', index='matchId', columns='teamPosition').reset_index().drop(columns=0)\n",
    "X_train_perlane['BOTTOM'] = np.where(X_train_perlane['BOTTOM'] >= 0, 1, -1)\n",
    "X_train_perlane['JUNGLE'] = np.where(X_train_perlane['JUNGLE'] >= 0, 1, -1)\n",
    "X_train_perlane['MIDDLE'] = np.where(X_train_perlane['MIDDLE'] >= 0, 1, -1)\n",
    "X_train_perlane['TOP'] = np.where(X_train_perlane['TOP'] >= 0, 1, -1)\n",
    "X_train_perlane['UTILITY'] = np.where(X_train_perlane['UTILITY'] >= 0, 1, -1)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId'])[variables]\n",
    "    .agg({ 'championLevel': 'sum', \n",
    "           'final_gold' : 'sum', \n",
    "           'final_xp': 'sum', # interchangable with final_lvl\n",
    "           'final_armor': 'sum', \n",
    "           'final_health': 'sum',\n",
    "           'final_atkdmg': 'sum',\n",
    "        #    'Assassin': 'sum',\n",
    "        #    'Fighter': 'sum',\n",
    "        #    'Mage': 'sum',\n",
    "        #    'Marksman': 'sum',\n",
    "        #    'Support': 'sum',\n",
    "        #    'Tank': 'sum'\n",
    "          })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "X_train = pd.merge(X_train, X_train_perlane, how='inner', on='matchId').reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>championLevel</th>\n",
       "      <th>final_gold</th>\n",
       "      <th>final_xp</th>\n",
       "      <th>final_armor</th>\n",
       "      <th>final_health</th>\n",
       "      <th>final_atkdmg</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>JUNGLE</th>\n",
       "      <th>MIDDLE</th>\n",
       "      <th>TOP</th>\n",
       "      <th>UTILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3393</td>\n",
       "      <td>-1614</td>\n",
       "      <td>27</td>\n",
       "      <td>228</td>\n",
       "      <td>-170</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2846</td>\n",
       "      <td>-258</td>\n",
       "      <td>-61</td>\n",
       "      <td>-778</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-973</td>\n",
       "      <td>-630</td>\n",
       "      <td>-25</td>\n",
       "      <td>-587</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>4102</td>\n",
       "      <td>1366</td>\n",
       "      <td>47</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1391</td>\n",
       "      <td>1070</td>\n",
       "      <td>4</td>\n",
       "      <td>475</td>\n",
       "      <td>-130</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  championLevel  final_gold  final_xp  final_armor  final_health  \\\n",
       "0        0            0.0       -3393     -1614           27           228   \n",
       "1        1            8.0        2846      -258          -61          -778   \n",
       "2        2            1.0        -973      -630          -25          -587   \n",
       "3        3           -3.0        4102      1366           47           480   \n",
       "4        4            7.0        1391      1070            4           475   \n",
       "\n",
       "   final_atkdmg  BOTTOM  JUNGLE  MIDDLE  TOP  UTILITY  \n",
       "0          -170      -1      -1       1   -1       -1  \n",
       "1            48       1       1       1   -1        1  \n",
       "2            29       1      -1      -1   -1       -1  \n",
       "3             1       1       1      -1   -1        1  \n",
       "4          -130      -1       1      -1    1        1  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lastframe_lanes = Pipeline(\n",
    "    steps = [\n",
    "        #('pf', PolynomialFeatures(interaction_only = True, include_bias = False)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        #('logreg', LogisticRegression(penalty = 'l1', solver = 'saga', max_iter = 10000, C=0.05)) # this is to regularize and get some polynomial features to 0\n",
    "        ('logreg', LogisticRegression()) \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used this below to find out best C value is 0.05\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# gs = GridSearchCV(estimator = pipeline_lastframe_lanes, \n",
    "#                  param_grid = {'logreg__C': [1, 0.5, 0.1, 0.05, 0.01]},\n",
    "#                  scoring = 'accuracy')\n",
    "\n",
    "# gs.fit(X_train, y_train)\n",
    "\n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pf&#x27;,\n",
       "                 PolynomialFeatures(include_bias=False, interaction_only=True)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(C=0.05, max_iter=10000, penalty=&#x27;l1&#x27;,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pf&#x27;,\n",
       "                 PolynomialFeatures(include_bias=False, interaction_only=True)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logreg&#x27;,\n",
       "                 LogisticRegression(C=0.05, max_iter=10000, penalty=&#x27;l1&#x27;,\n",
       "                                    solver=&#x27;saga&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False, interaction_only=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.05, max_iter=10000, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pf',\n",
       "                 PolynomialFeatures(include_bias=False, interaction_only=True)),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=0.05, max_iter=10000, penalty='l1',\n",
       "                                    solver='saga'))])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lastframe_lanes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715875"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = pipeline_lastframe_lanes.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71625 0.7075  0.71    0.70625 0.72375 0.7425  0.70125 0.70375 0.72625\n",
      " 0.67375]\n",
      "0.711125\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = pipeline_lastframe_lanes,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to put this to test.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['championLevel','final_gold', 'final_xp', 'final_armor', 'final_health', 'final_atkdmg',\n",
    "             #'Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank'\n",
    "             ]\n",
    "\n",
    "X_test = pd.merge(X_test_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "#X_test = pd.merge(X_test, champion_types, how='inner', left_on='championId', right_on='key')\n",
    "X_test = pd.merge(X_test, test_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_test = pd.merge(X_test, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "X_test = X_test.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "# below doesn't make the model better\n",
    "# X_train[['Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank']] = X_train[['Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank']].multiply(X_train['championLevel'], axis='index')\n",
    "\n",
    "convert_team_values(X_test, variables)\n",
    "\n",
    "X_test_perlane = X_test.groupby(['matchId', 'teamPosition'])[['final_gold']].sum().pivot_table(values='final_gold', index='matchId', columns='teamPosition').reset_index().drop(columns=0)\n",
    "X_test_perlane['BOTTOM'] = np.where(X_test_perlane['BOTTOM'] >= 0, 1, -1)\n",
    "X_test_perlane['JUNGLE'] = np.where(X_test_perlane['JUNGLE'] >= 0, 1, -1)\n",
    "X_test_perlane['MIDDLE'] = np.where(X_test_perlane['MIDDLE'] >= 0, 1, -1)\n",
    "X_test_perlane['TOP'] = np.where(X_test_perlane['TOP'] >= 0, 1, -1)\n",
    "X_test_perlane['UTILITY'] = np.where(X_test_perlane['UTILITY'] >= 0, 1, -1)\n",
    "\n",
    "X_test = (\n",
    "    X_test\n",
    "    .groupby(['matchId'])[variables]\n",
    "    .agg({ 'championLevel': 'sum', \n",
    "           'final_gold' : 'sum', \n",
    "           'final_xp': 'sum', # interchangable with final_lvl\n",
    "           'final_armor': 'sum', \n",
    "           'final_health': 'sum',\n",
    "           'final_atkdmg': 'sum',\n",
    "        #    'Assassin': 'sum',\n",
    "        #    'Fighter': 'sum',\n",
    "        #    'Mage': 'sum',\n",
    "        #    'Marksman': 'sum',\n",
    "        #    'Support': 'sum',\n",
    "        #    'Tank': 'sum'\n",
    "          })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "X_test = pd.merge(X_test, X_test_perlane, how='inner', on='matchId').reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_lastframe_lanes.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  winner\n",
       "0     8000     100\n",
       "1     8001     100\n",
       "2     8002     200\n",
       "3     8003     100\n",
       "4     8004     200"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['winner'] = y_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('../data/submission_including_frames_lanes_2023_03_26.csv', index=False)\n",
    "# submission.to_csv('../data/submission_including_frames_lanes_herotypes_2023_03_26.csv', index=False)\n",
    "# submission.to_csv('../data/submission_including_frames_lanes_interactions_2023_03_28.csv', index=False)\n",
    "# submission.to_csv('../data/submission_including_frames_lanes_interactions_reg_2023_03_28.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok one more attempt to better determine won/lost lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['championLevel','final_gold', 'final_xp', 'final_armor', 'final_health', 'final_atkdmg']\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "X_train = pd.merge(X_train, train_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "# attempting better \"lane won\" conditions\n",
    "X_train_lane_gold = X_train.groupby(['matchId', 'teamPosition'])[['final_gold']].sum().pivot_table(values='final_gold', index='matchId', columns='teamPosition').reset_index().drop(columns=0)\n",
    "X_train_lane_xp = X_train.groupby(['matchId', 'teamPosition'])[['final_xp']].sum().pivot_table(values='final_xp', index='matchId', columns='teamPosition').reset_index().drop(columns=0)\n",
    "\n",
    "\n",
    "X_train_perlane = pd.merge(X_train_lane_gold, X_train_lane_xp, how='inner', on='matchId')\n",
    "\n",
    "for lane in ['BOTTOM', 'JUNGLE', 'MIDDLE', 'TOP', 'UTILITY']:\n",
    "\n",
    "    conditions = [\n",
    "        (X_train_perlane[f'{lane}_x'] > 0) & (X_train_perlane[f'{lane}_y'] > 0),\n",
    "        (X_train_perlane[f'{lane}_x'] > 0) & (X_train_perlane[f'{lane}_y'] < 0),\n",
    "        (X_train_perlane[f'{lane}_x'] < 0) & (X_train_perlane[f'{lane}_y'] > 0),\n",
    "        (X_train_perlane[f'{lane}_x'] < 0) & (X_train_perlane[f'{lane}_y'] < 0)\n",
    "    ]\n",
    "\n",
    "    values = [1, 0, 0, -1]\n",
    "\n",
    "    X_train_perlane[f'{lane}'] = np.select(conditions, values)\n",
    "\n",
    "X_train_perlane = X_train_perlane[['matchId', 'BOTTOM', 'JUNGLE', 'MIDDLE', 'TOP', 'UTILITY']]\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId'])[variables]\n",
    "    .agg({ 'championLevel': 'sum', \n",
    "           'final_gold' : 'sum', \n",
    "           'final_xp': 'sum', # interchangable with final_lvl\n",
    "           'final_armor': 'sum', \n",
    "           'final_health': 'sum',\n",
    "           'final_atkdmg': 'sum'\n",
    "          })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "X_train = pd.merge(X_train, X_train_perlane, how='inner', on='matchId').reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lastframe_lanes = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lastframe_lanes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.710875"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = pipeline_lastframe_lanes.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7125  0.69375 0.7275  0.71625 0.7175  0.7375  0.68375 0.69625 0.72125\n",
      " 0.67625]\n",
      "0.7082499999999999\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = pipeline_lastframe_lanes,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just testing ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['final_gold', 'final_xp', 'final_armor', 'final_health', 'final_atkdmg', 'final_enemycontrolled'\n",
    "             ]\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "X_train = pd.merge(X_train, train_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "#X_train = X_train.groupby(['matchId', 'teamPosition'])[['final_gold']].sum().pivot_table(values='final_gold', index='matchId', columns='teamPosition').reset_index()\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId'])[variables]\n",
    "    .agg({ 'final_gold' : 'sum', \n",
    "           'final_xp': 'sum', # interchangable with final_lvl\n",
    "           'final_armor': 'sum', \n",
    "           'final_health': 'sum',\n",
    "           'final_atkdmg': 'sum',\n",
    "           'final_enemycontrolled': 'sum'\n",
    "          })\n",
    "    .reset_index()\n",
    ").reset_index(drop = True)\n",
    "\n",
    "#X_train = pd.merge(X_train, X_train_perlane, how='inner', on='matchId').reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>final_gold</th>\n",
       "      <th>final_xp</th>\n",
       "      <th>final_armor</th>\n",
       "      <th>final_health</th>\n",
       "      <th>final_atkdmg</th>\n",
       "      <th>final_enemycontrolled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3393</td>\n",
       "      <td>-1614</td>\n",
       "      <td>27</td>\n",
       "      <td>228</td>\n",
       "      <td>-170</td>\n",
       "      <td>67664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2846</td>\n",
       "      <td>-258</td>\n",
       "      <td>-61</td>\n",
       "      <td>-778</td>\n",
       "      <td>48</td>\n",
       "      <td>-61783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-973</td>\n",
       "      <td>-630</td>\n",
       "      <td>-25</td>\n",
       "      <td>-587</td>\n",
       "      <td>29</td>\n",
       "      <td>-132630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4102</td>\n",
       "      <td>1366</td>\n",
       "      <td>47</td>\n",
       "      <td>480</td>\n",
       "      <td>1</td>\n",
       "      <td>-39616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1391</td>\n",
       "      <td>1070</td>\n",
       "      <td>4</td>\n",
       "      <td>475</td>\n",
       "      <td>-130</td>\n",
       "      <td>16629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  final_gold  final_xp  final_armor  final_health  final_atkdmg  \\\n",
       "0        0       -3393     -1614           27           228          -170   \n",
       "1        1        2846      -258          -61          -778            48   \n",
       "2        2        -973      -630          -25          -587            29   \n",
       "3        3        4102      1366           47           480             1   \n",
       "4        4        1391      1070            4           475          -130   \n",
       "\n",
       "   final_enemycontrolled  \n",
       "0                  67664  \n",
       "1                 -61783  \n",
       "2                -132630  \n",
       "3                 -39616  \n",
       "4                  16629  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lastframe_lanes = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logreg', LogisticRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;logreg&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('logreg', LogisticRegression())])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_lastframe_lanes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71875 0.69375 0.72    0.7025  0.705   0.74625 0.68625 0.7075  0.72125\n",
      " 0.67625]\n",
      "0.7077499999999999\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = pipeline_lastframe_lanes,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to add wards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_events = pd.read_csv('../data/training_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['wards_placed', 'wards_killed', 'turretplates_destroyed', 'elite_monsters_killed']\n",
    "\n",
    "convert_team_values(training_events, vars)\n",
    "\n",
    "training_events = training_events.groupby('matchId')[vars].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['championLevel','final_gold', 'final_xp', 'final_armor', 'final_health', 'final_atkdmg',\n",
    "             'final_atkspd', 'final_health', 'final_healthrgn', 'final_lifesteal', 'final_mgpen', 'final_mgres', 'final_ms',\n",
    "             'final_dmgdone', 'final_dmgtaken', 'final_truedmgdone', 'final_truedmgtaken', 'final_lvl',\n",
    "#             'Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank'\n",
    "             ]\n",
    "\n",
    "X_train = pd.merge(X_train_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "#X_train = pd.merge(X_train, champion_types, how='inner', left_on='championId', right_on='key')\n",
    "X_train = pd.merge(X_train, train_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_train = pd.merge(X_train, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "X_train = X_train.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "# below doesn't make the model better\n",
    "# X_train[['Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank']] = X_train[['Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank']].multiply(X_train['championLevel'], axis='index')\n",
    "\n",
    "convert_team_values(X_train, variables)\n",
    "\n",
    "X_train_perlane = X_train.groupby(['matchId', 'teamPosition'])[['final_gold']].sum().pivot_table(values='final_gold', index='matchId', columns='teamPosition').reset_index().drop(columns=0)\n",
    "X_train_perlane['BOTTOM'] = np.where(X_train_perlane['BOTTOM'] >= 0, 1, -1)\n",
    "X_train_perlane['JUNGLE'] = np.where(X_train_perlane['JUNGLE'] >= 0, 1, -1)\n",
    "X_train_perlane['MIDDLE'] = np.where(X_train_perlane['MIDDLE'] >= 0, 1, -1)\n",
    "X_train_perlane['TOP'] = np.where(X_train_perlane['TOP'] >= 0, 1, -1)\n",
    "X_train_perlane['UTILITY'] = np.where(X_train_perlane['UTILITY'] >= 0, 1, -1)\n",
    "\n",
    "X_train = (\n",
    "    X_train\n",
    "    .groupby(['matchId'])[variables]\n",
    "    .agg({ 'championLevel': 'sum', \n",
    "           'final_gold' : 'sum', \n",
    "           'final_xp': 'sum', # interchangable with final_lvl\n",
    "           'final_armor': 'sum', \n",
    "           'final_health': 'sum',\n",
    "           'final_atkdmg': 'sum',\n",
    "          #  'Assassin': 'sum',\n",
    "          #  'Fighter': 'sum',\n",
    "          #  'Mage': 'sum',\n",
    "          #  'Marksman': 'sum',\n",
    "          #  'Support': 'sum',\n",
    "          #  'Tank': 'sum',\n",
    "           'final_atkspd': 'sum',\n",
    "           'final_health': 'sum',\n",
    "           'final_healthrgn': 'sum',\n",
    "           'final_lifesteal': 'sum',\n",
    "           'final_mgpen': 'sum',\n",
    "           'final_mgres': 'sum',\n",
    "           'final_ms': 'sum',\n",
    "            'final_dmgdone': 'sum',\n",
    "            'final_dmgtaken': 'sum',\n",
    "            'final_truedmgdone': 'sum',\n",
    "            'final_truedmgtaken': 'sum',\n",
    "            'final_lvl': 'sum'\n",
    "          })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "X_train = pd.merge(X_train, X_train_perlane, how='inner', on='matchId').reset_index(drop = True)\n",
    "X_train = pd.merge(X_train, training_events, how='inner', on='matchId').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>championLevel</th>\n",
       "      <th>final_gold</th>\n",
       "      <th>final_xp</th>\n",
       "      <th>final_armor</th>\n",
       "      <th>final_health</th>\n",
       "      <th>final_atkdmg</th>\n",
       "      <th>final_atkspd</th>\n",
       "      <th>final_healthrgn</th>\n",
       "      <th>final_lifesteal</th>\n",
       "      <th>...</th>\n",
       "      <th>final_lvl</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>JUNGLE</th>\n",
       "      <th>MIDDLE</th>\n",
       "      <th>TOP</th>\n",
       "      <th>UTILITY</th>\n",
       "      <th>wards_placed</th>\n",
       "      <th>wards_killed</th>\n",
       "      <th>turretplates_destroyed</th>\n",
       "      <th>elite_monsters_killed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3393</td>\n",
       "      <td>-1614</td>\n",
       "      <td>27</td>\n",
       "      <td>12308</td>\n",
       "      <td>-170</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-64</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2846</td>\n",
       "      <td>-258</td>\n",
       "      <td>-61</td>\n",
       "      <td>12050</td>\n",
       "      <td>48</td>\n",
       "      <td>103</td>\n",
       "      <td>-95</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-973</td>\n",
       "      <td>-630</td>\n",
       "      <td>-25</td>\n",
       "      <td>12413</td>\n",
       "      <td>29</td>\n",
       "      <td>-58</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>4102</td>\n",
       "      <td>1366</td>\n",
       "      <td>47</td>\n",
       "      <td>12000</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1391</td>\n",
       "      <td>1070</td>\n",
       "      <td>4</td>\n",
       "      <td>12109</td>\n",
       "      <td>-130</td>\n",
       "      <td>-88</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  championLevel  final_gold  final_xp  final_armor  final_health  \\\n",
       "0        0            0.0       -3393     -1614           27         12308   \n",
       "1        1            8.0        2846      -258          -61         12050   \n",
       "2        2            1.0        -973      -630          -25         12413   \n",
       "3        3           -3.0        4102      1366           47         12000   \n",
       "4        4            7.0        1391      1070            4         12109   \n",
       "\n",
       "   final_atkdmg  final_atkspd  final_healthrgn  final_lifesteal  ...  \\\n",
       "0          -170            23                2              -16  ...   \n",
       "1            48           103              -95                9  ...   \n",
       "2            29           -58               13                1  ...   \n",
       "3             1           162               31                8  ...   \n",
       "4          -130           -88               82                0  ...   \n",
       "\n",
       "   final_lvl  BOTTOM  JUNGLE  MIDDLE  TOP  UTILITY  wards_placed  \\\n",
       "0         -1      -1      -1       1   -1       -1           -64   \n",
       "1          0       1       1       1   -1        1             1   \n",
       "2         -2       1      -1      -1   -1       -1             4   \n",
       "3          2       1       1      -1   -1        1             4   \n",
       "4          3      -1       1      -1    1        1             4   \n",
       "\n",
       "   wards_killed  turretplates_destroyed  elite_monsters_killed  \n",
       "0            -1                      -2                     -1  \n",
       "1             0                      -1                     -1  \n",
       "2             1                      -2                      1  \n",
       "3             0                       2                      0  \n",
       "4             0                      -1                     -1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_neuralnetwork = Pipeline(\n",
    "    steps = [\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('nn', MLPClassifier(verbose = True,\n",
    "                             hidden_layer_sizes = (100, 100, 100),\n",
    "                             activation = 'tanh',\n",
    "                             max_iter = 10000))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_frames_lanes = Pipeline(\n",
    "    steps = [\n",
    "        #('pf', PolynomialFeatures(interaction_only = True, include_bias = False)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        #('logreg', LogisticRegression(penalty = 'l1', solver = 'saga', max_iter = 10000, C=0.05)) # this is to regularize and get some polynomial features to 0\n",
    "        ('logreg', LogisticRegression()) \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.61019271\n",
      "Iteration 2, loss = 0.57854907\n",
      "Iteration 3, loss = 0.57442100\n",
      "Iteration 4, loss = 0.56679515\n",
      "Iteration 5, loss = 0.56763913\n",
      "Iteration 6, loss = 0.56368981\n",
      "Iteration 7, loss = 0.56219946\n",
      "Iteration 8, loss = 0.56332839\n",
      "Iteration 9, loss = 0.56215489\n",
      "Iteration 10, loss = 0.56610935\n",
      "Iteration 11, loss = 0.56167408\n",
      "Iteration 12, loss = 0.55947760\n",
      "Iteration 13, loss = 0.56029098\n",
      "Iteration 14, loss = 0.56653601\n",
      "Iteration 15, loss = 0.56097927\n",
      "Iteration 16, loss = 0.56052132\n",
      "Iteration 17, loss = 0.56196663\n",
      "Iteration 18, loss = 0.55892603\n",
      "Iteration 19, loss = 0.55792073\n",
      "Iteration 20, loss = 0.55591075\n",
      "Iteration 21, loss = 0.55837006\n",
      "Iteration 22, loss = 0.55788586\n",
      "Iteration 23, loss = 0.55736543\n",
      "Iteration 24, loss = 0.55785622\n",
      "Iteration 25, loss = 0.56030719\n",
      "Iteration 26, loss = 0.56172630\n",
      "Iteration 27, loss = 0.55619708\n",
      "Iteration 28, loss = 0.55774606\n",
      "Iteration 29, loss = 0.55577476\n",
      "Iteration 30, loss = 0.55607030\n",
      "Iteration 31, loss = 0.55631671\n",
      "Iteration 32, loss = 0.56743423\n",
      "Iteration 33, loss = 0.55573018\n",
      "Iteration 34, loss = 0.55456811\n",
      "Iteration 35, loss = 0.55410165\n",
      "Iteration 36, loss = 0.55472989\n",
      "Iteration 37, loss = 0.55407389\n",
      "Iteration 38, loss = 0.55723247\n",
      "Iteration 39, loss = 0.55634256\n",
      "Iteration 40, loss = 0.55773977\n",
      "Iteration 41, loss = 0.55472844\n",
      "Iteration 42, loss = 0.55468356\n",
      "Iteration 43, loss = 0.55452290\n",
      "Iteration 44, loss = 0.55576132\n",
      "Iteration 45, loss = 0.55508371\n",
      "Iteration 46, loss = 0.55423814\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;background-color: white;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;nn&#x27;,\n",
       "                 MLPClassifier(activation=&#x27;tanh&#x27;,\n",
       "                               hidden_layer_sizes=(100, 100, 100),\n",
       "                               max_iter=10000, verbose=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;nn&#x27;,\n",
       "                 MLPClassifier(activation=&#x27;tanh&#x27;,\n",
       "                               hidden_layer_sizes=(100, 100, 100),\n",
       "                               max_iter=10000, verbose=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-85\" type=\"checkbox\" ><label for=\"sk-estimator-id-85\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-86\" type=\"checkbox\" ><label for=\"sk-estimator-id-86\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, hidden_layer_sizes=(100, 100, 100),\n",
       "              max_iter=10000, verbose=True)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                ('nn',\n",
       "                 MLPClassifier(activation='tanh',\n",
       "                               hidden_layer_sizes=(100, 100, 100),\n",
       "                               max_iter=10000, verbose=True))])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_neuralnetwork.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7145"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    y_true = y_train,\n",
    "    y_pred = pipeline_neuralnetwork.predict(X_train)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.60183325\n",
      "Iteration 2, loss = 0.57448732\n",
      "Iteration 3, loss = 0.56759126\n",
      "Iteration 4, loss = 0.56525413\n",
      "Iteration 5, loss = 0.56537085\n",
      "Iteration 6, loss = 0.57082294\n",
      "Iteration 7, loss = 0.55989042\n",
      "Iteration 8, loss = 0.56099043\n",
      "Iteration 9, loss = 0.56102401\n",
      "Iteration 10, loss = 0.56193262\n",
      "Iteration 11, loss = 0.56056259\n",
      "Iteration 12, loss = 0.55767112\n",
      "Iteration 13, loss = 0.56382595\n",
      "Iteration 14, loss = 0.56081993\n",
      "Iteration 15, loss = 0.55811175\n",
      "Iteration 16, loss = 0.55773554\n",
      "Iteration 17, loss = 0.56049518\n",
      "Iteration 18, loss = 0.55725971\n",
      "Iteration 19, loss = 0.55803488\n",
      "Iteration 20, loss = 0.55555016\n",
      "Iteration 21, loss = 0.55607114\n",
      "Iteration 22, loss = 0.55609477\n",
      "Iteration 23, loss = 0.55446387\n",
      "Iteration 24, loss = 0.55434388\n",
      "Iteration 25, loss = 0.55502594\n",
      "Iteration 26, loss = 0.55309927\n",
      "Iteration 27, loss = 0.55703565\n",
      "Iteration 28, loss = 0.55305037\n",
      "Iteration 29, loss = 0.55487363\n",
      "Iteration 30, loss = 0.55496022\n",
      "Iteration 31, loss = 0.55222023\n",
      "Iteration 32, loss = 0.55549511\n",
      "Iteration 33, loss = 0.55352806\n",
      "Iteration 34, loss = 0.55470880\n",
      "Iteration 35, loss = 0.55211259\n",
      "Iteration 36, loss = 0.55327368\n",
      "Iteration 37, loss = 0.55896968\n",
      "Iteration 38, loss = 0.55767079\n",
      "Iteration 39, loss = 0.55342386\n",
      "Iteration 40, loss = 0.55234605\n",
      "Iteration 41, loss = 0.55315287\n",
      "Iteration 42, loss = 0.55461853\n",
      "Iteration 43, loss = 0.55370855\n",
      "Iteration 44, loss = 0.55617733\n",
      "Iteration 45, loss = 0.55572906\n",
      "Iteration 46, loss = 0.55380204\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61135416\n",
      "Iteration 2, loss = 0.58020584\n",
      "Iteration 3, loss = 0.57190335\n",
      "Iteration 4, loss = 0.57084684\n",
      "Iteration 5, loss = 0.56602879\n",
      "Iteration 6, loss = 0.56340005\n",
      "Iteration 7, loss = 0.56728060\n",
      "Iteration 8, loss = 0.56156026\n",
      "Iteration 9, loss = 0.56313011\n",
      "Iteration 10, loss = 0.56136543\n",
      "Iteration 11, loss = 0.56239862\n",
      "Iteration 12, loss = 0.56375163\n",
      "Iteration 13, loss = 0.55981012\n",
      "Iteration 14, loss = 0.56237834\n",
      "Iteration 15, loss = 0.55904598\n",
      "Iteration 16, loss = 0.56611300\n",
      "Iteration 17, loss = 0.56025870\n",
      "Iteration 18, loss = 0.55797548\n",
      "Iteration 19, loss = 0.55453851\n",
      "Iteration 20, loss = 0.55862510\n",
      "Iteration 21, loss = 0.55826909\n",
      "Iteration 22, loss = 0.56218784\n",
      "Iteration 23, loss = 0.55605652\n",
      "Iteration 24, loss = 0.55416441\n",
      "Iteration 25, loss = 0.55371516\n",
      "Iteration 26, loss = 0.55261214\n",
      "Iteration 27, loss = 0.55338595\n",
      "Iteration 28, loss = 0.55546594\n",
      "Iteration 29, loss = 0.55420759\n",
      "Iteration 30, loss = 0.55340124\n",
      "Iteration 31, loss = 0.55432404\n",
      "Iteration 32, loss = 0.55381373\n",
      "Iteration 33, loss = 0.55554522\n",
      "Iteration 34, loss = 0.55574944\n",
      "Iteration 35, loss = 0.55285705\n",
      "Iteration 36, loss = 0.55110510\n",
      "Iteration 37, loss = 0.55195847\n",
      "Iteration 38, loss = 0.55203924\n",
      "Iteration 39, loss = 0.55392903\n",
      "Iteration 40, loss = 0.55318648\n",
      "Iteration 41, loss = 0.55126175\n",
      "Iteration 42, loss = 0.55360038\n",
      "Iteration 43, loss = 0.55342481\n",
      "Iteration 44, loss = 0.55324977\n",
      "Iteration 45, loss = 0.55241388\n",
      "Iteration 46, loss = 0.55242210\n",
      "Iteration 47, loss = 0.55124915\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.60581216\n",
      "Iteration 2, loss = 0.57858479\n",
      "Iteration 3, loss = 0.57382363\n",
      "Iteration 4, loss = 0.57336238\n",
      "Iteration 5, loss = 0.56943442\n",
      "Iteration 6, loss = 0.56568811\n",
      "Iteration 7, loss = 0.57526908\n",
      "Iteration 8, loss = 0.56461428\n",
      "Iteration 9, loss = 0.56436992\n",
      "Iteration 10, loss = 0.56675117\n",
      "Iteration 11, loss = 0.56845948\n",
      "Iteration 12, loss = 0.56191896\n",
      "Iteration 13, loss = 0.56123599\n",
      "Iteration 14, loss = 0.56372088\n",
      "Iteration 15, loss = 0.56242181\n",
      "Iteration 16, loss = 0.56288572\n",
      "Iteration 17, loss = 0.56807364\n",
      "Iteration 18, loss = 0.56408147\n",
      "Iteration 19, loss = 0.56184320\n",
      "Iteration 20, loss = 0.56110900\n",
      "Iteration 21, loss = 0.56187706\n",
      "Iteration 22, loss = 0.56055555\n",
      "Iteration 23, loss = 0.55726857\n",
      "Iteration 24, loss = 0.55724852\n",
      "Iteration 25, loss = 0.55676440\n",
      "Iteration 26, loss = 0.55979611\n",
      "Iteration 27, loss = 0.55829403\n",
      "Iteration 28, loss = 0.56117208\n",
      "Iteration 29, loss = 0.55904857\n",
      "Iteration 30, loss = 0.55935517\n",
      "Iteration 31, loss = 0.55673323\n",
      "Iteration 32, loss = 0.56051125\n",
      "Iteration 33, loss = 0.56156017\n",
      "Iteration 34, loss = 0.55754980\n",
      "Iteration 35, loss = 0.55631290\n",
      "Iteration 36, loss = 0.55601697\n",
      "Iteration 37, loss = 0.55685498\n",
      "Iteration 38, loss = 0.55634587\n",
      "Iteration 39, loss = 0.55624053\n",
      "Iteration 40, loss = 0.55453212\n",
      "Iteration 41, loss = 0.55920919\n",
      "Iteration 42, loss = 0.55507015\n",
      "Iteration 43, loss = 0.55678532\n",
      "Iteration 44, loss = 0.55351166\n",
      "Iteration 45, loss = 0.55893721\n",
      "Iteration 46, loss = 0.55543024\n",
      "Iteration 47, loss = 0.55675182\n",
      "Iteration 48, loss = 0.55726990\n",
      "Iteration 49, loss = 0.55509547\n",
      "Iteration 50, loss = 0.55670314\n",
      "Iteration 51, loss = 0.55783752\n",
      "Iteration 52, loss = 0.55468254\n",
      "Iteration 53, loss = 0.55437444\n",
      "Iteration 54, loss = 0.55383438\n",
      "Iteration 55, loss = 0.55375547\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.62871798\n",
      "Iteration 2, loss = 0.58475857\n",
      "Iteration 3, loss = 0.57788240\n",
      "Iteration 4, loss = 0.57367263\n",
      "Iteration 5, loss = 0.57883659\n",
      "Iteration 6, loss = 0.56759156\n",
      "Iteration 7, loss = 0.56589681\n",
      "Iteration 8, loss = 0.58538754\n",
      "Iteration 9, loss = 0.56666823\n",
      "Iteration 10, loss = 0.57063326\n",
      "Iteration 11, loss = 0.56573849\n",
      "Iteration 12, loss = 0.56220088\n",
      "Iteration 13, loss = 0.56136254\n",
      "Iteration 14, loss = 0.55949319\n",
      "Iteration 15, loss = 0.56125700\n",
      "Iteration 16, loss = 0.56513118\n",
      "Iteration 17, loss = 0.56606224\n",
      "Iteration 18, loss = 0.56230429\n",
      "Iteration 19, loss = 0.55936266\n",
      "Iteration 20, loss = 0.55823692\n",
      "Iteration 21, loss = 0.56371867\n",
      "Iteration 22, loss = 0.56541722\n",
      "Iteration 23, loss = 0.56158643\n",
      "Iteration 24, loss = 0.56041492\n",
      "Iteration 25, loss = 0.56007688\n",
      "Iteration 26, loss = 0.55818506\n",
      "Iteration 27, loss = 0.55791191\n",
      "Iteration 28, loss = 0.56162812\n",
      "Iteration 29, loss = 0.56020037\n",
      "Iteration 30, loss = 0.55721998\n",
      "Iteration 31, loss = 0.55777216\n",
      "Iteration 32, loss = 0.55626430\n",
      "Iteration 33, loss = 0.56159513\n",
      "Iteration 34, loss = 0.55905882\n",
      "Iteration 35, loss = 0.56104141\n",
      "Iteration 36, loss = 0.55612944\n",
      "Iteration 37, loss = 0.55879219\n",
      "Iteration 38, loss = 0.55554656\n",
      "Iteration 39, loss = 0.55521910\n",
      "Iteration 40, loss = 0.55670676\n",
      "Iteration 41, loss = 0.55864752\n",
      "Iteration 42, loss = 0.56454914\n",
      "Iteration 43, loss = 0.55632687\n",
      "Iteration 44, loss = 0.55417799\n",
      "Iteration 45, loss = 0.55622809\n",
      "Iteration 46, loss = 0.55690444\n",
      "Iteration 47, loss = 0.55728998\n",
      "Iteration 48, loss = 0.55603095\n",
      "Iteration 49, loss = 0.55327035\n",
      "Iteration 50, loss = 0.55844301\n",
      "Iteration 51, loss = 0.55619988\n",
      "Iteration 52, loss = 0.55910448\n",
      "Iteration 53, loss = 0.56084150\n",
      "Iteration 54, loss = 0.55699088\n",
      "Iteration 55, loss = 0.55263064\n",
      "Iteration 56, loss = 0.55375014\n",
      "Iteration 57, loss = 0.55618455\n",
      "Iteration 58, loss = 0.55471248\n",
      "Iteration 59, loss = 0.55456633\n",
      "Iteration 60, loss = 0.55318881\n",
      "Iteration 61, loss = 0.55754136\n",
      "Iteration 62, loss = 0.55413108\n",
      "Iteration 63, loss = 0.55361312\n",
      "Iteration 64, loss = 0.55304255\n",
      "Iteration 65, loss = 0.55396246\n",
      "Iteration 66, loss = 0.55603696\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61474276\n",
      "Iteration 2, loss = 0.58027542\n",
      "Iteration 3, loss = 0.57494588\n",
      "Iteration 4, loss = 0.57017458\n",
      "Iteration 5, loss = 0.56723138\n",
      "Iteration 6, loss = 0.57198416\n",
      "Iteration 7, loss = 0.56968481\n",
      "Iteration 8, loss = 0.56431351\n",
      "Iteration 9, loss = 0.56260368\n",
      "Iteration 10, loss = 0.55984374\n",
      "Iteration 11, loss = 0.55924922\n",
      "Iteration 12, loss = 0.55990720\n",
      "Iteration 13, loss = 0.56396142\n",
      "Iteration 14, loss = 0.56239543\n",
      "Iteration 15, loss = 0.56035921\n",
      "Iteration 16, loss = 0.55884900\n",
      "Iteration 17, loss = 0.55681405\n",
      "Iteration 18, loss = 0.55855005\n",
      "Iteration 19, loss = 0.55652945\n",
      "Iteration 20, loss = 0.55621237\n",
      "Iteration 21, loss = 0.55861851\n",
      "Iteration 22, loss = 0.55841121\n",
      "Iteration 23, loss = 0.55793857\n",
      "Iteration 24, loss = 0.55460483\n",
      "Iteration 25, loss = 0.55480079\n",
      "Iteration 26, loss = 0.55607110\n",
      "Iteration 27, loss = 0.55866714\n",
      "Iteration 28, loss = 0.55514885\n",
      "Iteration 29, loss = 0.55579525\n",
      "Iteration 30, loss = 0.55809465\n",
      "Iteration 31, loss = 0.55759450\n",
      "Iteration 32, loss = 0.55551365\n",
      "Iteration 33, loss = 0.55738458\n",
      "Iteration 34, loss = 0.55582049\n",
      "Iteration 35, loss = 0.55392955\n",
      "Iteration 36, loss = 0.55210255\n",
      "Iteration 37, loss = 0.55613384\n",
      "Iteration 38, loss = 0.55288533\n",
      "Iteration 39, loss = 0.55251606\n",
      "Iteration 40, loss = 0.55500598\n",
      "Iteration 41, loss = 0.55346482\n",
      "Iteration 42, loss = 0.55292991\n",
      "Iteration 43, loss = 0.55586156\n",
      "Iteration 44, loss = 0.55444127\n",
      "Iteration 45, loss = 0.55290661\n",
      "Iteration 46, loss = 0.55370078\n",
      "Iteration 47, loss = 0.55514751\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61706817\n",
      "Iteration 2, loss = 0.58422801\n",
      "Iteration 3, loss = 0.57971088\n",
      "Iteration 4, loss = 0.57099265\n",
      "Iteration 5, loss = 0.57062723\n",
      "Iteration 6, loss = 0.56885093\n",
      "Iteration 7, loss = 0.56542760\n",
      "Iteration 8, loss = 0.58002600\n",
      "Iteration 9, loss = 0.56418469\n",
      "Iteration 10, loss = 0.56832893\n",
      "Iteration 11, loss = 0.57058645\n",
      "Iteration 12, loss = 0.56439188\n",
      "Iteration 13, loss = 0.56643729\n",
      "Iteration 14, loss = 0.56157195\n",
      "Iteration 15, loss = 0.56004194\n",
      "Iteration 16, loss = 0.56274926\n",
      "Iteration 17, loss = 0.55940617\n",
      "Iteration 18, loss = 0.55898165\n",
      "Iteration 19, loss = 0.56107836\n",
      "Iteration 20, loss = 0.55724799\n",
      "Iteration 21, loss = 0.55989281\n",
      "Iteration 22, loss = 0.56122708\n",
      "Iteration 23, loss = 0.55739910\n",
      "Iteration 24, loss = 0.55896238\n",
      "Iteration 25, loss = 0.56141596\n",
      "Iteration 26, loss = 0.55802403\n",
      "Iteration 27, loss = 0.56125270\n",
      "Iteration 28, loss = 0.56126178\n",
      "Iteration 29, loss = 0.56252473\n",
      "Iteration 30, loss = 0.56021297\n",
      "Iteration 31, loss = 0.56372044\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.62264460\n",
      "Iteration 2, loss = 0.57521008\n",
      "Iteration 3, loss = 0.56873398\n",
      "Iteration 4, loss = 0.56509219\n",
      "Iteration 5, loss = 0.56413414\n",
      "Iteration 6, loss = 0.55905048\n",
      "Iteration 7, loss = 0.56213399\n",
      "Iteration 8, loss = 0.56344002\n",
      "Iteration 9, loss = 0.56310574\n",
      "Iteration 10, loss = 0.56088150\n",
      "Iteration 11, loss = 0.55761961\n",
      "Iteration 12, loss = 0.55833952\n",
      "Iteration 13, loss = 0.55604318\n",
      "Iteration 14, loss = 0.55519520\n",
      "Iteration 15, loss = 0.55879709\n",
      "Iteration 16, loss = 0.55696982\n",
      "Iteration 17, loss = 0.55429943\n",
      "Iteration 18, loss = 0.55348674\n",
      "Iteration 19, loss = 0.55866728\n",
      "Iteration 20, loss = 0.55587783\n",
      "Iteration 21, loss = 0.55229460\n",
      "Iteration 22, loss = 0.55528647\n",
      "Iteration 23, loss = 0.55279085\n",
      "Iteration 24, loss = 0.55760995\n",
      "Iteration 25, loss = 0.55281327\n",
      "Iteration 26, loss = 0.55426854\n",
      "Iteration 27, loss = 0.55424494\n",
      "Iteration 28, loss = 0.55533773\n",
      "Iteration 29, loss = 0.55611412\n",
      "Iteration 30, loss = 0.55331824\n",
      "Iteration 31, loss = 0.55511545\n",
      "Iteration 32, loss = 0.55106409\n",
      "Iteration 33, loss = 0.55079492\n",
      "Iteration 34, loss = 0.55368206\n",
      "Iteration 35, loss = 0.55983809\n",
      "Iteration 36, loss = 0.55256725\n",
      "Iteration 37, loss = 0.55034462\n",
      "Iteration 38, loss = 0.55164659\n",
      "Iteration 39, loss = 0.55351726\n",
      "Iteration 40, loss = 0.55065953\n",
      "Iteration 41, loss = 0.55300020\n",
      "Iteration 42, loss = 0.55105296\n",
      "Iteration 43, loss = 0.55334439\n",
      "Iteration 44, loss = 0.55213757\n",
      "Iteration 45, loss = 0.55345981\n",
      "Iteration 46, loss = 0.55184419\n",
      "Iteration 47, loss = 0.55520094\n",
      "Iteration 48, loss = 0.55202931\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.61632911\n",
      "Iteration 2, loss = 0.58076223\n",
      "Iteration 3, loss = 0.57764159\n",
      "Iteration 4, loss = 0.57100829\n",
      "Iteration 5, loss = 0.57221405\n",
      "Iteration 6, loss = 0.57262598\n",
      "Iteration 7, loss = 0.56717513\n",
      "Iteration 8, loss = 0.56506820\n",
      "Iteration 9, loss = 0.56344911\n",
      "Iteration 10, loss = 0.56760454\n",
      "Iteration 11, loss = 0.56185421\n",
      "Iteration 12, loss = 0.55943874\n",
      "Iteration 13, loss = 0.55990525\n",
      "Iteration 14, loss = 0.55833183\n",
      "Iteration 15, loss = 0.55585351\n",
      "Iteration 16, loss = 0.55830041\n",
      "Iteration 17, loss = 0.55968784\n",
      "Iteration 18, loss = 0.55937331\n",
      "Iteration 19, loss = 0.55851652\n",
      "Iteration 20, loss = 0.56192711\n",
      "Iteration 21, loss = 0.55811148\n",
      "Iteration 22, loss = 0.56627420\n",
      "Iteration 23, loss = 0.56025898\n",
      "Iteration 24, loss = 0.55501783\n",
      "Iteration 25, loss = 0.55606212\n",
      "Iteration 26, loss = 0.56112552\n",
      "Iteration 27, loss = 0.55529061\n",
      "Iteration 28, loss = 0.55581109\n",
      "Iteration 29, loss = 0.55716945\n",
      "Iteration 30, loss = 0.55461035\n",
      "Iteration 31, loss = 0.55522648\n",
      "Iteration 32, loss = 0.55464680\n",
      "Iteration 33, loss = 0.55332953\n",
      "Iteration 34, loss = 0.55544579\n",
      "Iteration 35, loss = 0.55556726\n",
      "Iteration 36, loss = 0.55488524\n",
      "Iteration 37, loss = 0.55492576\n",
      "Iteration 38, loss = 0.56162158\n",
      "Iteration 39, loss = 0.55557051\n",
      "Iteration 40, loss = 0.55421936\n",
      "Iteration 41, loss = 0.55278288\n",
      "Iteration 42, loss = 0.55493084\n",
      "Iteration 43, loss = 0.55261447\n",
      "Iteration 44, loss = 0.55701782\n",
      "Iteration 45, loss = 0.55650955\n",
      "Iteration 46, loss = 0.55219188\n",
      "Iteration 47, loss = 0.55436261\n",
      "Iteration 48, loss = 0.55160109\n",
      "Iteration 49, loss = 0.55164510\n",
      "Iteration 50, loss = 0.55143080\n",
      "Iteration 51, loss = 0.55712399\n",
      "Iteration 52, loss = 0.55854865\n",
      "Iteration 53, loss = 0.55408252\n",
      "Iteration 54, loss = 0.55537344\n",
      "Iteration 55, loss = 0.55580743\n",
      "Iteration 56, loss = 0.55726911\n",
      "Iteration 57, loss = 0.55319219\n",
      "Iteration 58, loss = 0.55165259\n",
      "Iteration 59, loss = 0.55755776\n",
      "Iteration 60, loss = 0.55641725\n",
      "Iteration 61, loss = 0.55255080\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.60756997\n",
      "Iteration 2, loss = 0.57900665\n",
      "Iteration 3, loss = 0.57267346\n",
      "Iteration 4, loss = 0.57487872\n",
      "Iteration 5, loss = 0.57181229\n",
      "Iteration 6, loss = 0.56388645\n",
      "Iteration 7, loss = 0.56390247\n",
      "Iteration 8, loss = 0.56184457\n",
      "Iteration 9, loss = 0.56340236\n",
      "Iteration 10, loss = 0.56247096\n",
      "Iteration 11, loss = 0.55951914\n",
      "Iteration 12, loss = 0.56208416\n",
      "Iteration 13, loss = 0.55938560\n",
      "Iteration 14, loss = 0.55791638\n",
      "Iteration 15, loss = 0.56422607\n",
      "Iteration 16, loss = 0.56569739\n",
      "Iteration 17, loss = 0.55865025\n",
      "Iteration 18, loss = 0.55994438\n",
      "Iteration 19, loss = 0.55991841\n",
      "Iteration 20, loss = 0.55987353\n",
      "Iteration 21, loss = 0.56350438\n",
      "Iteration 22, loss = 0.55886710\n",
      "Iteration 23, loss = 0.56137429\n",
      "Iteration 24, loss = 0.56426093\n",
      "Iteration 25, loss = 0.55703986\n",
      "Iteration 26, loss = 0.55777047\n",
      "Iteration 27, loss = 0.55777754\n",
      "Iteration 28, loss = 0.55819425\n",
      "Iteration 29, loss = 0.55974429\n",
      "Iteration 30, loss = 0.55706730\n",
      "Iteration 31, loss = 0.55719217\n",
      "Iteration 32, loss = 0.55591764\n",
      "Iteration 33, loss = 0.55937403\n",
      "Iteration 34, loss = 0.56077597\n",
      "Iteration 35, loss = 0.55986654\n",
      "Iteration 36, loss = 0.55981885\n",
      "Iteration 37, loss = 0.56086999\n",
      "Iteration 38, loss = 0.55789492\n",
      "Iteration 39, loss = 0.55752112\n",
      "Iteration 40, loss = 0.55560229\n",
      "Iteration 41, loss = 0.55740798\n",
      "Iteration 42, loss = 0.55469249\n",
      "Iteration 43, loss = 0.55438920\n",
      "Iteration 44, loss = 0.55455746\n",
      "Iteration 45, loss = 0.55602346\n",
      "Iteration 46, loss = 0.55370690\n",
      "Iteration 47, loss = 0.55585046\n",
      "Iteration 48, loss = 0.55688356\n",
      "Iteration 49, loss = 0.55483934\n",
      "Iteration 50, loss = 0.55556687\n",
      "Iteration 51, loss = 0.55428500\n",
      "Iteration 52, loss = 0.55553372\n",
      "Iteration 53, loss = 0.55458586\n",
      "Iteration 54, loss = 0.55480186\n",
      "Iteration 55, loss = 0.55745741\n",
      "Iteration 56, loss = 0.55373296\n",
      "Iteration 57, loss = 0.55328538\n",
      "Iteration 58, loss = 0.55401995\n",
      "Iteration 59, loss = 0.55244985\n",
      "Iteration 60, loss = 0.55326260\n",
      "Iteration 61, loss = 0.55321501\n",
      "Iteration 62, loss = 0.55476648\n",
      "Iteration 63, loss = 0.55875702\n",
      "Iteration 64, loss = 0.55702148\n",
      "Iteration 65, loss = 0.55453251\n",
      "Iteration 66, loss = 0.55273224\n",
      "Iteration 67, loss = 0.55289683\n",
      "Iteration 68, loss = 0.55188448\n",
      "Iteration 69, loss = 0.55287612\n",
      "Iteration 70, loss = 0.56272253\n",
      "Iteration 71, loss = 0.55320466\n",
      "Iteration 72, loss = 0.55182285\n",
      "Iteration 73, loss = 0.55157206\n",
      "Iteration 74, loss = 0.55181328\n",
      "Iteration 75, loss = 0.55284673\n",
      "Iteration 76, loss = 0.55193655\n",
      "Iteration 77, loss = 0.55217609\n",
      "Iteration 78, loss = 0.55239892\n",
      "Iteration 79, loss = 0.55074085\n",
      "Iteration 80, loss = 0.55239034\n",
      "Iteration 81, loss = 0.55089580\n",
      "Iteration 82, loss = 0.55147842\n",
      "Iteration 83, loss = 0.55012797\n",
      "Iteration 84, loss = 0.55263772\n",
      "Iteration 85, loss = 0.55031954\n",
      "Iteration 86, loss = 0.55169806\n",
      "Iteration 87, loss = 0.55127869\n",
      "Iteration 88, loss = 0.55268431\n",
      "Iteration 89, loss = 0.54857543\n",
      "Iteration 90, loss = 0.54977704\n",
      "Iteration 91, loss = 0.55424113\n",
      "Iteration 92, loss = 0.54946648\n",
      "Iteration 93, loss = 0.54742777\n",
      "Iteration 94, loss = 0.54780307\n",
      "Iteration 95, loss = 0.55169646\n",
      "Iteration 96, loss = 0.54872132\n",
      "Iteration 97, loss = 0.54688511\n",
      "Iteration 98, loss = 0.54921875\n",
      "Iteration 99, loss = 0.54972148\n",
      "Iteration 100, loss = 0.54662401\n",
      "Iteration 101, loss = 0.54597376\n",
      "Iteration 102, loss = 0.54744478\n",
      "Iteration 103, loss = 0.54631267\n",
      "Iteration 104, loss = 0.54784198\n",
      "Iteration 105, loss = 0.54562447\n",
      "Iteration 106, loss = 0.54561050\n",
      "Iteration 107, loss = 0.54573531\n",
      "Iteration 108, loss = 0.54569613\n",
      "Iteration 109, loss = 0.54631817\n",
      "Iteration 110, loss = 0.54518091\n",
      "Iteration 111, loss = 0.54352879\n",
      "Iteration 112, loss = 0.54367294\n",
      "Iteration 113, loss = 0.54255875\n",
      "Iteration 114, loss = 0.54116395\n",
      "Iteration 115, loss = 0.54125127\n",
      "Iteration 116, loss = 0.54189156\n",
      "Iteration 117, loss = 0.54457875\n",
      "Iteration 118, loss = 0.54083200\n",
      "Iteration 119, loss = 0.54092387\n",
      "Iteration 120, loss = 0.54130737\n",
      "Iteration 121, loss = 0.53837037\n",
      "Iteration 122, loss = 0.54090383\n",
      "Iteration 123, loss = 0.54060218\n",
      "Iteration 124, loss = 0.53941683\n",
      "Iteration 125, loss = 0.53987503\n",
      "Iteration 126, loss = 0.53796353\n",
      "Iteration 127, loss = 0.53651626\n",
      "Iteration 128, loss = 0.53626297\n",
      "Iteration 129, loss = 0.53650989\n",
      "Iteration 130, loss = 0.53839779\n",
      "Iteration 131, loss = 0.53808084\n",
      "Iteration 132, loss = 0.53564815\n",
      "Iteration 133, loss = 0.53641921\n",
      "Iteration 134, loss = 0.54008537\n",
      "Iteration 135, loss = 0.53461273\n",
      "Iteration 136, loss = 0.53341095\n",
      "Iteration 137, loss = 0.53517514\n",
      "Iteration 138, loss = 0.53408128\n",
      "Iteration 139, loss = 0.53254793\n",
      "Iteration 140, loss = 0.53028092\n",
      "Iteration 141, loss = 0.53483802\n",
      "Iteration 142, loss = 0.53149162\n",
      "Iteration 143, loss = 0.53126295\n",
      "Iteration 144, loss = 0.52988334\n",
      "Iteration 145, loss = 0.53439274\n",
      "Iteration 146, loss = 0.53091428\n",
      "Iteration 147, loss = 0.52867397\n",
      "Iteration 148, loss = 0.53114938\n",
      "Iteration 149, loss = 0.52749397\n",
      "Iteration 150, loss = 0.52476373\n",
      "Iteration 151, loss = 0.52751146\n",
      "Iteration 152, loss = 0.52677461\n",
      "Iteration 153, loss = 0.52364432\n",
      "Iteration 154, loss = 0.52448344\n",
      "Iteration 155, loss = 0.52422679\n",
      "Iteration 156, loss = 0.52730226\n",
      "Iteration 157, loss = 0.52512968\n",
      "Iteration 158, loss = 0.52186074\n",
      "Iteration 159, loss = 0.52087220\n",
      "Iteration 160, loss = 0.51912514\n",
      "Iteration 161, loss = 0.52117213\n",
      "Iteration 162, loss = 0.51743225\n",
      "Iteration 163, loss = 0.52137689\n",
      "Iteration 164, loss = 0.51837850\n",
      "Iteration 165, loss = 0.51617346\n",
      "Iteration 166, loss = 0.51588901\n",
      "Iteration 167, loss = 0.51322504\n",
      "Iteration 168, loss = 0.51470407\n",
      "Iteration 169, loss = 0.51312410\n",
      "Iteration 170, loss = 0.51190263\n",
      "Iteration 171, loss = 0.51489090\n",
      "Iteration 172, loss = 0.51309843\n",
      "Iteration 173, loss = 0.51059674\n",
      "Iteration 174, loss = 0.50979169\n",
      "Iteration 175, loss = 0.51329599\n",
      "Iteration 176, loss = 0.50891409\n",
      "Iteration 177, loss = 0.50979350\n",
      "Iteration 178, loss = 0.50632806\n",
      "Iteration 179, loss = 0.50605785\n",
      "Iteration 180, loss = 0.50662004\n",
      "Iteration 181, loss = 0.50592232\n",
      "Iteration 182, loss = 0.50450930\n",
      "Iteration 183, loss = 0.50240973\n",
      "Iteration 184, loss = 0.49968068\n",
      "Iteration 185, loss = 0.50464551\n",
      "Iteration 186, loss = 0.49980656\n",
      "Iteration 187, loss = 0.49783368\n",
      "Iteration 188, loss = 0.49780794\n",
      "Iteration 189, loss = 0.49474859\n",
      "Iteration 190, loss = 0.49488839\n",
      "Iteration 191, loss = 0.50049732\n",
      "Iteration 192, loss = 0.49514039\n",
      "Iteration 193, loss = 0.49650713\n",
      "Iteration 194, loss = 0.49310928\n",
      "Iteration 195, loss = 0.49406560\n",
      "Iteration 196, loss = 0.48886543\n",
      "Iteration 197, loss = 0.48787340\n",
      "Iteration 198, loss = 0.48677006\n",
      "Iteration 199, loss = 0.48955999\n",
      "Iteration 200, loss = 0.49216208\n",
      "Iteration 201, loss = 0.48793411\n",
      "Iteration 202, loss = 0.48736977\n",
      "Iteration 203, loss = 0.48659036\n",
      "Iteration 204, loss = 0.48101660\n",
      "Iteration 205, loss = 0.47984777\n",
      "Iteration 206, loss = 0.47916463\n",
      "Iteration 207, loss = 0.47940004\n",
      "Iteration 208, loss = 0.48135709\n",
      "Iteration 209, loss = 0.47763371\n",
      "Iteration 210, loss = 0.47634443\n",
      "Iteration 211, loss = 0.47490238\n",
      "Iteration 212, loss = 0.47790919\n",
      "Iteration 213, loss = 0.47573184\n",
      "Iteration 214, loss = 0.47136155\n",
      "Iteration 215, loss = 0.46973838\n",
      "Iteration 216, loss = 0.46951645\n",
      "Iteration 217, loss = 0.46814749\n",
      "Iteration 218, loss = 0.46691519\n",
      "Iteration 219, loss = 0.46692533\n",
      "Iteration 220, loss = 0.46464845\n",
      "Iteration 221, loss = 0.46129000\n",
      "Iteration 222, loss = 0.46051321\n",
      "Iteration 223, loss = 0.45697184\n",
      "Iteration 224, loss = 0.45863813\n",
      "Iteration 225, loss = 0.45547929\n",
      "Iteration 226, loss = 0.45541754\n",
      "Iteration 227, loss = 0.45501103\n",
      "Iteration 228, loss = 0.45500085\n",
      "Iteration 229, loss = 0.45413630\n",
      "Iteration 230, loss = 0.44968145\n",
      "Iteration 231, loss = 0.44773377\n",
      "Iteration 232, loss = 0.44877248\n",
      "Iteration 233, loss = 0.44591012\n",
      "Iteration 234, loss = 0.44130496\n",
      "Iteration 235, loss = 0.44235412\n",
      "Iteration 236, loss = 0.44027018\n",
      "Iteration 237, loss = 0.43972026\n",
      "Iteration 238, loss = 0.44227135\n",
      "Iteration 239, loss = 0.43420144\n",
      "Iteration 240, loss = 0.43488319\n",
      "Iteration 241, loss = 0.43712643\n",
      "Iteration 242, loss = 0.43127551\n",
      "Iteration 243, loss = 0.43132244\n",
      "Iteration 244, loss = 0.42869633\n",
      "Iteration 245, loss = 0.42677095\n",
      "Iteration 246, loss = 0.42397637\n",
      "Iteration 247, loss = 0.42742295\n",
      "Iteration 248, loss = 0.42346257\n",
      "Iteration 249, loss = 0.42135196\n",
      "Iteration 250, loss = 0.41913526\n",
      "Iteration 251, loss = 0.42121755\n",
      "Iteration 252, loss = 0.41523222\n",
      "Iteration 253, loss = 0.41405547\n",
      "Iteration 254, loss = 0.41415923\n",
      "Iteration 255, loss = 0.41058030\n",
      "Iteration 256, loss = 0.41297414\n",
      "Iteration 257, loss = 0.41196306\n",
      "Iteration 258, loss = 0.40351819\n",
      "Iteration 259, loss = 0.40616327\n",
      "Iteration 260, loss = 0.40629039\n",
      "Iteration 261, loss = 0.40355213\n",
      "Iteration 262, loss = 0.40033155\n",
      "Iteration 263, loss = 0.39784012\n",
      "Iteration 264, loss = 0.39401345\n",
      "Iteration 265, loss = 0.39141224\n",
      "Iteration 266, loss = 0.39776058\n",
      "Iteration 267, loss = 0.38763860\n",
      "Iteration 268, loss = 0.38625574\n",
      "Iteration 269, loss = 0.38265367\n",
      "Iteration 270, loss = 0.38401296\n",
      "Iteration 271, loss = 0.38313777\n",
      "Iteration 272, loss = 0.37516417\n",
      "Iteration 273, loss = 0.37580076\n",
      "Iteration 274, loss = 0.37476343\n",
      "Iteration 275, loss = 0.37306747\n",
      "Iteration 276, loss = 0.36666050\n",
      "Iteration 277, loss = 0.36923898\n",
      "Iteration 278, loss = 0.37002294\n",
      "Iteration 279, loss = 0.36287795\n",
      "Iteration 280, loss = 0.36630044\n",
      "Iteration 281, loss = 0.36236772\n",
      "Iteration 282, loss = 0.35657964\n",
      "Iteration 283, loss = 0.35654231\n",
      "Iteration 284, loss = 0.35041266\n",
      "Iteration 285, loss = 0.35182373\n",
      "Iteration 286, loss = 0.35038848\n",
      "Iteration 287, loss = 0.34826683\n",
      "Iteration 288, loss = 0.34793319\n",
      "Iteration 289, loss = 0.34421136\n",
      "Iteration 290, loss = 0.34131139\n",
      "Iteration 291, loss = 0.34372863\n",
      "Iteration 292, loss = 0.33615523\n",
      "Iteration 293, loss = 0.33560162\n",
      "Iteration 294, loss = 0.33044379\n",
      "Iteration 295, loss = 0.33722786\n",
      "Iteration 296, loss = 0.32985170\n",
      "Iteration 297, loss = 0.32409311\n",
      "Iteration 298, loss = 0.32465103\n",
      "Iteration 299, loss = 0.32225053\n",
      "Iteration 300, loss = 0.32015222\n",
      "Iteration 301, loss = 0.31734984\n",
      "Iteration 302, loss = 0.31827165\n",
      "Iteration 303, loss = 0.31660016\n",
      "Iteration 304, loss = 0.30922817\n",
      "Iteration 305, loss = 0.31011726\n",
      "Iteration 306, loss = 0.30953200\n",
      "Iteration 307, loss = 0.31362938\n",
      "Iteration 308, loss = 0.30183512\n",
      "Iteration 309, loss = 0.29995356\n",
      "Iteration 310, loss = 0.29911057\n",
      "Iteration 311, loss = 0.29690743\n",
      "Iteration 312, loss = 0.29199300\n",
      "Iteration 313, loss = 0.28992215\n",
      "Iteration 314, loss = 0.29574230\n",
      "Iteration 315, loss = 0.29066229\n",
      "Iteration 316, loss = 0.28385435\n",
      "Iteration 317, loss = 0.28154812\n",
      "Iteration 318, loss = 0.27798505\n",
      "Iteration 319, loss = 0.27691553\n",
      "Iteration 320, loss = 0.27560805\n",
      "Iteration 321, loss = 0.27366557\n",
      "Iteration 322, loss = 0.26845293\n",
      "Iteration 323, loss = 0.26823085\n",
      "Iteration 324, loss = 0.26554338\n",
      "Iteration 325, loss = 0.26374685\n",
      "Iteration 326, loss = 0.26395821\n",
      "Iteration 327, loss = 0.25764871\n",
      "Iteration 328, loss = 0.25539493\n",
      "Iteration 329, loss = 0.25408506\n",
      "Iteration 330, loss = 0.25088386\n",
      "Iteration 331, loss = 0.24983610\n",
      "Iteration 332, loss = 0.24616503\n",
      "Iteration 333, loss = 0.24337560\n",
      "Iteration 334, loss = 0.24149843\n",
      "Iteration 335, loss = 0.24418888\n",
      "Iteration 336, loss = 0.23709987\n",
      "Iteration 337, loss = 0.23528491\n",
      "Iteration 338, loss = 0.23892446\n",
      "Iteration 339, loss = 0.23246473\n",
      "Iteration 340, loss = 0.22892281\n",
      "Iteration 341, loss = 0.23017675\n",
      "Iteration 342, loss = 0.23123844\n",
      "Iteration 343, loss = 0.22152126\n",
      "Iteration 344, loss = 0.21959598\n",
      "Iteration 345, loss = 0.21941349\n",
      "Iteration 346, loss = 0.21741573\n",
      "Iteration 347, loss = 0.21819949\n",
      "Iteration 348, loss = 0.21426513\n",
      "Iteration 349, loss = 0.21164294\n",
      "Iteration 350, loss = 0.21148880\n",
      "Iteration 351, loss = 0.20676147\n",
      "Iteration 352, loss = 0.20668818\n",
      "Iteration 353, loss = 0.20423224\n",
      "Iteration 354, loss = 0.20016823\n",
      "Iteration 355, loss = 0.20387417\n",
      "Iteration 356, loss = 0.20038023\n",
      "Iteration 357, loss = 0.19801719\n",
      "Iteration 358, loss = 0.19037756\n",
      "Iteration 359, loss = 0.18977804\n",
      "Iteration 360, loss = 0.18762874\n",
      "Iteration 361, loss = 0.18346585\n",
      "Iteration 362, loss = 0.18869122\n",
      "Iteration 363, loss = 0.18668944\n",
      "Iteration 364, loss = 0.17565687\n",
      "Iteration 365, loss = 0.17671056\n",
      "Iteration 366, loss = 0.17669068\n",
      "Iteration 367, loss = 0.17245272\n",
      "Iteration 368, loss = 0.17306254\n",
      "Iteration 369, loss = 0.16913756\n",
      "Iteration 370, loss = 0.16791294\n",
      "Iteration 371, loss = 0.16503096\n",
      "Iteration 372, loss = 0.16437679\n",
      "Iteration 373, loss = 0.16494193\n",
      "Iteration 374, loss = 0.16238119\n",
      "Iteration 375, loss = 0.15749555\n",
      "Iteration 376, loss = 0.15673607\n",
      "Iteration 377, loss = 0.15770596\n",
      "Iteration 378, loss = 0.15443038\n",
      "Iteration 379, loss = 0.15213763\n",
      "Iteration 380, loss = 0.15095899\n",
      "Iteration 381, loss = 0.14774329\n",
      "Iteration 382, loss = 0.14655220\n",
      "Iteration 383, loss = 0.14443079\n",
      "Iteration 384, loss = 0.14599702\n",
      "Iteration 385, loss = 0.14375337\n",
      "Iteration 386, loss = 0.13879314\n",
      "Iteration 387, loss = 0.14094395\n",
      "Iteration 388, loss = 0.13669273\n",
      "Iteration 389, loss = 0.13526346\n",
      "Iteration 390, loss = 0.13415959\n",
      "Iteration 391, loss = 0.13089098\n",
      "Iteration 392, loss = 0.12977413\n",
      "Iteration 393, loss = 0.12482505\n",
      "Iteration 394, loss = 0.12470390\n",
      "Iteration 395, loss = 0.12529203\n",
      "Iteration 396, loss = 0.12313387\n",
      "Iteration 397, loss = 0.11786361\n",
      "Iteration 398, loss = 0.11857919\n",
      "Iteration 399, loss = 0.12198882\n",
      "Iteration 400, loss = 0.11577937\n",
      "Iteration 401, loss = 0.11353421\n",
      "Iteration 402, loss = 0.11253465\n",
      "Iteration 403, loss = 0.10995345\n",
      "Iteration 404, loss = 0.10940694\n",
      "Iteration 405, loss = 0.10997799\n",
      "Iteration 406, loss = 0.10737982\n",
      "Iteration 407, loss = 0.10758822\n",
      "Iteration 408, loss = 0.10614614\n",
      "Iteration 409, loss = 0.10465337\n",
      "Iteration 410, loss = 0.09920424\n",
      "Iteration 411, loss = 0.10110434\n",
      "Iteration 412, loss = 0.10014798\n",
      "Iteration 413, loss = 0.09809452\n",
      "Iteration 414, loss = 0.09457969\n",
      "Iteration 415, loss = 0.09092385\n",
      "Iteration 416, loss = 0.09107768\n",
      "Iteration 417, loss = 0.09141979\n",
      "Iteration 418, loss = 0.09121467\n",
      "Iteration 419, loss = 0.08708764\n",
      "Iteration 420, loss = 0.08541226\n",
      "Iteration 421, loss = 0.08504272\n",
      "Iteration 422, loss = 0.08533976\n",
      "Iteration 423, loss = 0.08174678\n",
      "Iteration 424, loss = 0.07987490\n",
      "Iteration 425, loss = 0.07936860\n",
      "Iteration 426, loss = 0.08393213\n",
      "Iteration 427, loss = 0.07869636\n",
      "Iteration 428, loss = 0.07908863\n",
      "Iteration 429, loss = 0.07576142\n",
      "Iteration 430, loss = 0.07342272\n",
      "Iteration 431, loss = 0.07271012\n",
      "Iteration 432, loss = 0.07066536\n",
      "Iteration 433, loss = 0.07158301\n",
      "Iteration 434, loss = 0.06990411\n",
      "Iteration 435, loss = 0.07148820\n",
      "Iteration 436, loss = 0.06663824\n",
      "Iteration 437, loss = 0.06616824\n",
      "Iteration 438, loss = 0.06569806\n",
      "Iteration 439, loss = 0.06458063\n",
      "Iteration 440, loss = 0.06316160\n",
      "Iteration 441, loss = 0.06302782\n",
      "Iteration 442, loss = 0.06030602\n",
      "Iteration 443, loss = 0.05863397\n",
      "Iteration 444, loss = 0.05819828\n",
      "Iteration 445, loss = 0.05779242\n",
      "Iteration 446, loss = 0.05766465\n",
      "Iteration 447, loss = 0.05645039\n",
      "Iteration 448, loss = 0.05640323\n",
      "Iteration 449, loss = 0.05455698\n",
      "Iteration 450, loss = 0.05271726\n",
      "Iteration 451, loss = 0.05328401\n",
      "Iteration 452, loss = 0.05242959\n",
      "Iteration 453, loss = 0.05185466\n",
      "Iteration 454, loss = 0.05157756\n",
      "Iteration 455, loss = 0.05060828\n",
      "Iteration 456, loss = 0.04827717\n",
      "Iteration 457, loss = 0.04822080\n",
      "Iteration 458, loss = 0.04712906\n",
      "Iteration 459, loss = 0.04656253\n",
      "Iteration 460, loss = 0.04512519\n",
      "Iteration 461, loss = 0.04436881\n",
      "Iteration 462, loss = 0.04254488\n",
      "Iteration 463, loss = 0.04300569\n",
      "Iteration 464, loss = 0.04400649\n",
      "Iteration 465, loss = 0.04279383\n",
      "Iteration 466, loss = 0.04165478\n",
      "Iteration 467, loss = 0.04023928\n",
      "Iteration 468, loss = 0.04041857\n",
      "Iteration 469, loss = 0.03893357\n",
      "Iteration 470, loss = 0.03900459\n",
      "Iteration 471, loss = 0.03717218\n",
      "Iteration 472, loss = 0.03568948\n",
      "Iteration 473, loss = 0.03589375\n",
      "Iteration 474, loss = 0.03541319\n",
      "Iteration 475, loss = 0.03568371\n",
      "Iteration 476, loss = 0.03509900\n",
      "Iteration 477, loss = 0.03373642\n",
      "Iteration 478, loss = 0.03466663\n",
      "Iteration 479, loss = 0.03324961\n",
      "Iteration 480, loss = 0.03202076\n",
      "Iteration 481, loss = 0.03279565\n",
      "Iteration 482, loss = 0.03253707\n",
      "Iteration 483, loss = 0.03124226\n",
      "Iteration 484, loss = 0.03025316\n",
      "Iteration 485, loss = 0.02891418\n",
      "Iteration 486, loss = 0.02809984\n",
      "Iteration 487, loss = 0.02825543\n",
      "Iteration 488, loss = 0.02920211\n",
      "Iteration 489, loss = 0.03051861\n",
      "Iteration 490, loss = 0.02663276\n",
      "Iteration 491, loss = 0.02658068\n",
      "Iteration 492, loss = 0.02536413\n",
      "Iteration 493, loss = 0.02477246\n",
      "Iteration 494, loss = 0.02458930\n",
      "Iteration 495, loss = 0.02497214\n",
      "Iteration 496, loss = 0.02408443\n",
      "Iteration 497, loss = 0.02381328\n",
      "Iteration 498, loss = 0.02326900\n",
      "Iteration 499, loss = 0.02306438\n",
      "Iteration 500, loss = 0.02355953\n",
      "Iteration 501, loss = 0.02323934\n",
      "Iteration 502, loss = 0.02265991\n",
      "Iteration 503, loss = 0.02136650\n",
      "Iteration 504, loss = 0.02050281\n",
      "Iteration 505, loss = 0.02030562\n",
      "Iteration 506, loss = 0.02074722\n",
      "Iteration 507, loss = 0.02052910\n",
      "Iteration 508, loss = 0.02050696\n",
      "Iteration 509, loss = 0.01952919\n",
      "Iteration 510, loss = 0.01905432\n",
      "Iteration 511, loss = 0.01900339\n",
      "Iteration 512, loss = 0.01920785\n",
      "Iteration 513, loss = 0.01925019\n",
      "Iteration 514, loss = 0.01816009\n",
      "Iteration 515, loss = 0.01736959\n",
      "Iteration 516, loss = 0.01753797\n",
      "Iteration 517, loss = 0.01795599\n",
      "Iteration 518, loss = 0.01714762\n",
      "Iteration 519, loss = 0.01590629\n",
      "Iteration 520, loss = 0.01592729\n",
      "Iteration 521, loss = 0.01574709\n",
      "Iteration 522, loss = 0.01536498\n",
      "Iteration 523, loss = 0.01494067\n",
      "Iteration 524, loss = 0.01482855\n",
      "Iteration 525, loss = 0.01525340\n",
      "Iteration 526, loss = 0.01444706\n",
      "Iteration 527, loss = 0.01450071\n",
      "Iteration 528, loss = 0.01419655\n",
      "Iteration 529, loss = 0.01382007\n",
      "Iteration 530, loss = 0.01379655\n",
      "Iteration 531, loss = 0.01376037\n",
      "Iteration 532, loss = 0.01316546\n",
      "Iteration 533, loss = 0.01256747\n",
      "Iteration 534, loss = 0.01244061\n",
      "Iteration 535, loss = 0.01229179\n",
      "Iteration 536, loss = 0.01223170\n",
      "Iteration 537, loss = 0.01192798\n",
      "Iteration 538, loss = 0.01125542\n",
      "Iteration 539, loss = 0.01133575\n",
      "Iteration 540, loss = 0.01167641\n",
      "Iteration 541, loss = 0.01147844\n",
      "Iteration 542, loss = 0.01080890\n",
      "Iteration 543, loss = 0.01077859\n",
      "Iteration 544, loss = 0.01034875\n",
      "Iteration 545, loss = 0.01031623\n",
      "Iteration 546, loss = 0.01010064\n",
      "Iteration 547, loss = 0.01006417\n",
      "Iteration 548, loss = 0.00985082\n",
      "Iteration 549, loss = 0.00971901\n",
      "Iteration 550, loss = 0.00996434\n",
      "Iteration 551, loss = 0.00959339\n",
      "Iteration 552, loss = 0.00897709\n",
      "Iteration 553, loss = 0.01227463\n",
      "Iteration 554, loss = 0.02084936\n",
      "Iteration 555, loss = 0.04823389\n",
      "Iteration 556, loss = 0.03304731\n",
      "Iteration 557, loss = 0.01775998\n",
      "Iteration 558, loss = 0.01214114\n",
      "Iteration 559, loss = 0.00886239\n",
      "Iteration 560, loss = 0.00817785\n",
      "Iteration 561, loss = 0.00777906\n",
      "Iteration 562, loss = 0.00770359\n",
      "Iteration 563, loss = 0.00748944\n",
      "Iteration 564, loss = 0.00741563\n",
      "Iteration 565, loss = 0.00722158\n",
      "Iteration 566, loss = 0.00712368\n",
      "Iteration 567, loss = 0.00701277\n",
      "Iteration 568, loss = 0.00693201\n",
      "Iteration 569, loss = 0.00688508\n",
      "Iteration 570, loss = 0.00671946\n",
      "Iteration 571, loss = 0.00666749\n",
      "Iteration 572, loss = 0.00657431\n",
      "Iteration 573, loss = 0.00660443\n",
      "Iteration 574, loss = 0.00640809\n",
      "Iteration 575, loss = 0.00644177\n",
      "Iteration 576, loss = 0.00630686\n",
      "Iteration 577, loss = 0.00621296\n",
      "Iteration 578, loss = 0.00614962\n",
      "Iteration 579, loss = 0.00607388\n",
      "Iteration 580, loss = 0.00599471\n",
      "Iteration 581, loss = 0.00592918\n",
      "Iteration 582, loss = 0.00587807\n",
      "Iteration 583, loss = 0.00577875\n",
      "Iteration 584, loss = 0.00569593\n",
      "Iteration 585, loss = 0.00572996\n",
      "Iteration 586, loss = 0.00570343\n",
      "Iteration 587, loss = 0.00571245\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.60946078\n",
      "Iteration 2, loss = 0.57430425\n",
      "Iteration 3, loss = 0.56563201\n",
      "Iteration 4, loss = 0.56149459\n",
      "Iteration 5, loss = 0.55896580\n",
      "Iteration 6, loss = 0.55731659\n",
      "Iteration 7, loss = 0.55476243\n",
      "Iteration 8, loss = 0.55557644\n",
      "Iteration 9, loss = 0.55383574\n",
      "Iteration 10, loss = 0.55436957\n",
      "Iteration 11, loss = 0.55386903\n",
      "Iteration 12, loss = 0.55402954\n",
      "Iteration 13, loss = 0.55578195\n",
      "Iteration 14, loss = 0.55199894\n",
      "Iteration 15, loss = 0.55127047\n",
      "Iteration 16, loss = 0.55088687\n",
      "Iteration 17, loss = 0.55031970\n",
      "Iteration 18, loss = 0.55283588\n",
      "Iteration 19, loss = 0.54934152\n",
      "Iteration 20, loss = 0.55055986\n",
      "Iteration 21, loss = 0.55049790\n",
      "Iteration 22, loss = 0.55220092\n",
      "Iteration 23, loss = 0.55007243\n",
      "Iteration 24, loss = 0.54970030\n",
      "Iteration 25, loss = 0.55563599\n",
      "Iteration 26, loss = 0.55027608\n",
      "Iteration 27, loss = 0.54965308\n",
      "Iteration 28, loss = 0.54980669\n",
      "Iteration 29, loss = 0.55125476\n",
      "Iteration 30, loss = 0.54939321\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "[0.70625 0.71875 0.71    0.72375 0.70625 0.73375 0.7075  0.705   0.66\n",
      " 0.6825 ]\n",
      "0.705375\n"
     ]
    }
   ],
   "source": [
    "summoner_cv_scores = cross_val_score(\n",
    "    estimator = pipeline_neuralnetwork,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold\n",
    ")\n",
    "\n",
    "print(summoner_cv_scores)\n",
    "print(np.mean(summoner_cv_scores))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the above on testing ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_events = pd.read_csv('../data/testing_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['wards_placed', 'wards_killed', 'turretplates_destroyed', 'elite_monsters_killed']\n",
    "\n",
    "convert_team_values(testing_events, vars)\n",
    "\n",
    "testing_events = testing_events.groupby('matchId')[vars].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['championLevel','final_gold', 'final_xp', 'final_armor', 'final_health', 'final_atkdmg',\n",
    "             'final_atkspd', 'final_health', 'final_healthrgn', 'final_lifesteal', 'final_mgpen', 'final_mgres', 'final_ms',\n",
    "             'final_dmgdone', 'final_dmgtaken', 'final_truedmgdone', 'final_truedmgtaken', 'final_lvl',\n",
    "             'Assassin', 'Fighter', 'Mage', 'Marksman', 'Support', 'Tank'\n",
    "             ]\n",
    "\n",
    "X_test = pd.merge(X_test_original, team_positions, how='inner', on=['matchId', 'participantId'])\n",
    "X_test = pd.merge(X_test, champion_types, how='inner', left_on='championId', right_on='key')\n",
    "X_test = pd.merge(X_test, test_last_frame_values, how='inner', on=['matchId', 'participantId'])\n",
    "X_test = pd.merge(X_test, champion_mastery, how='left', on=['summonerId', 'championId']).fillna(0)\n",
    "\n",
    "X_test = X_test.sort_values(['matchId', 'participantId'], ascending = [True, True]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "convert_team_values(X_test, variables)\n",
    "\n",
    "X_test_perlane = X_test.groupby(['matchId', 'teamPosition'])[['final_gold']].sum().pivot_table(values='final_gold', index='matchId', columns='teamPosition').reset_index().drop(columns=0)\n",
    "X_test_perlane['BOTTOM'] = np.where(X_test_perlane['BOTTOM'] >= 0, 1, -1)\n",
    "X_test_perlane['JUNGLE'] = np.where(X_test_perlane['JUNGLE'] >= 0, 1, -1)\n",
    "X_test_perlane['MIDDLE'] = np.where(X_test_perlane['MIDDLE'] >= 0, 1, -1)\n",
    "X_test_perlane['TOP'] = np.where(X_test_perlane['TOP'] >= 0, 1, -1)\n",
    "X_test_perlane['UTILITY'] = np.where(X_test_perlane['UTILITY'] >= 0, 1, -1)\n",
    "\n",
    "X_test = (\n",
    "    X_test\n",
    "    .groupby(['matchId'])[variables]\n",
    "    .agg({ 'championLevel': 'sum', \n",
    "           'final_gold' : 'sum', \n",
    "           'final_xp': 'sum', # interchangable with final_lvl\n",
    "           'final_armor': 'sum', \n",
    "           'final_health': 'sum',\n",
    "           'final_atkdmg': 'sum',\n",
    "           'Assassin': 'sum',\n",
    "           'Fighter': 'sum',\n",
    "           'Mage': 'sum',\n",
    "           'Marksman': 'sum',\n",
    "           'Support': 'sum',\n",
    "           'Tank': 'sum',\n",
    "           'final_atkspd': 'sum',\n",
    "           'final_health': 'sum',\n",
    "           'final_healthrgn': 'sum',\n",
    "           'final_lifesteal': 'sum',\n",
    "           'final_mgpen': 'sum',\n",
    "           'final_mgres': 'sum',\n",
    "           'final_ms': 'sum',\n",
    "            'final_dmgdone': 'sum',\n",
    "            'final_dmgtaken': 'sum',\n",
    "            'final_truedmgdone': 'sum',\n",
    "            'final_truedmgtaken': 'sum',\n",
    "            'final_lvl': 'sum'\n",
    "          })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "X_test = pd.merge(X_test, X_test_perlane, how='inner', on='matchId').reset_index(drop = True)\n",
    "X_test = pd.merge(X_test, testing_events, how='inner', on='matchId').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_neuralnetwork.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matchId  winner\n",
       "0     8000     200\n",
       "1     8001     100\n",
       "2     8002     200\n",
       "3     8003     200\n",
       "4     8004     200"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['winner'] = y_pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#submission.to_csv('../data/submission_first_neural_network_2023_03_28.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
